{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input\n",
    "\n",
    "> Defines the import for different source filetypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import imageio.v3 as iio\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from shapely import Polygon\n",
    "import roifile\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict, Tuple, Union, Optional, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FocusAreaPathRestrictions:\n",
    "    \n",
    "    @property\n",
    "    def supported_dir_names(self) -> List[str]:\n",
    "        supported_dir_names =  ['focus_area', 'focus_areas', 'focus-area', 'focus-areas', 'focus area', 'focus areas',\n",
    "                                'Focus_Area', 'Focus_Areas', 'Focus-Area', 'Focus-Areas', 'Focus Area', 'Focus Areas']\n",
    "        return supported_dir_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Data Handler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Data(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def _parse_loaded_data(self, loaded_data: Any) -> None:\n",
    "        pass\n",
    "\n",
    "    def __init__(self, filepath: Path, loaded_data: Any) -> None:\n",
    "        self.filepath = filepath\n",
    "        self._parse_loaded_data(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Recording(Data):\n",
    "\n",
    "    def _parse_loaded_data(self, loaded_data: np.ndarray) -> None:\n",
    "        self.zstack = loaded_data\n",
    "        self.estimated_bit_depth = self._estimate_bit_depth()\n",
    "        self.preview = self._create_brightness_and_contrast_enhanced_preview()\n",
    "\n",
    "\n",
    "    def _estimate_bit_depth(self) -> int:\n",
    "        max_bit_value = self.zstack.max()\n",
    "        if max_bit_value <= 255:\n",
    "            estimated_bit_depth = 255\n",
    "        elif max_bit_value <= 4095:\n",
    "            estimated_bit_depth = 4095\n",
    "        elif max_bit_value <= 65535:\n",
    "            estimated_bit_depth = 65535\n",
    "        else:\n",
    "            raise ValueError(f'Max bit value in recording found to be {max_bit_value}, but NA3 currently only handles up to 16-bit recordings!')\n",
    "        return estimated_bit_depth\n",
    "\n",
    "\n",
    "    def _create_brightness_and_contrast_enhanced_preview(self, percentile_for_adjustment: int=1) -> np.ndarray:\n",
    "        raw_image = self.zstack[0, :, :, :].copy() # ensure that dimensions are the same as for \".get_single_frame_as_preview()\"\n",
    "        lower_percentile_bit_value = np.percentile(raw_image, percentile_for_adjustment)\n",
    "        upper_percentile_bit_value = np.percentile(raw_image, 100-percentile_for_adjustment)\n",
    "        contrast_adjustment_factor = self.estimated_bit_depth / (upper_percentile_bit_value - lower_percentile_bit_value)\n",
    "        brightness_adjustment_factor = -(contrast_adjustment_factor * lower_percentile_bit_value)\n",
    "        raw_image_clipped_at_percentile_bit_values = self._clip_image_at_bit_values(raw_image, lower_percentile_bit_value, upper_percentile_bit_value)\n",
    "        brightness_contrast_adjusted_image = contrast_adjustment_factor * raw_image_clipped_at_percentile_bit_values + brightness_adjustment_factor\n",
    "        return brightness_contrast_adjusted_image\n",
    "        \n",
    "\n",
    "    def _compute_contrast_and_brightness_adjustment_factors(self, raw_image: np.ndarray, percentile_for_adjustment: int=1) -> Tuple[float, float]:\n",
    "        lower_percentile_bit_value = np.percentile(raw_image, percentile_for_adjustment)\n",
    "        upper_percentile_bit_value = np.percentile(raw_image, 100-percentile_for_adjustment)\n",
    "        contrast_adjustment = self.estimated_bit_depth / (upper_percentile_bit_value - lower_percentile_bit_value)\n",
    "        brightness_adjustment = -(contrast_adjustment * lower_percentile_bit_value)\n",
    "        return contrast_adjustment, brightness_adjustment\n",
    "\n",
    "\n",
    "    def _clip_image_at_bit_values(self, raw_image: np.ndarray, min_bit_value: float, max_bit_value: float) -> np.ndarray:\n",
    "        raw_image[raw_image <= min_bit_value] = min_bit_value\n",
    "        raw_image[raw_image >= max_bit_value] = max_bit_value\n",
    "        return raw_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ROI(Data):\n",
    "\n",
    "    def _parse_loaded_data(self, loaded_data: List[Tuple[int, int]]) -> None:\n",
    "        self.boundary_row_col_coords = loaded_data\n",
    "        self.as_polygon = self._convert_to_valid_polygon()\n",
    "\n",
    "\n",
    "    def _convert_to_valid_polygon(self) -> Polygon:\n",
    "        roi_as_polygon = Polygon(self.boundary_row_col_coords)\n",
    "        assert roi_as_polygon.is_valid, f'Something went wrong when trying to create a Polygon out of your ROI: {self.filepath}.'\n",
    "        return roi_as_polygon\n",
    "\n",
    "\n",
    "    def add_label_id(self, label_id: str) -> None:\n",
    "        assert type(label_id) == str, f'\"label_id\" must be a string. However, you passed {label_id} which is of type {type(label_id)}.'\n",
    "        setattr(self, 'label_id', label_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Data Loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataLoader(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_and_parse_file_content(self) -> Union[Data, List[Data]]:\n",
    "        # This method will be called when the data should be loaded for analysis\n",
    "        pass\n",
    "\n",
    "    def __init__(self, filepath: Path) -> None:\n",
    "        self.filepath = filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GridWrapperROILoader(DataLoader):\n",
    "\n",
    "    def set_configs_for_grid_creation(self, image_width: int, image_height: int, window_size: int) -> None:\n",
    "        self.configs = {}\n",
    "        self._add_to_configs_and_create_as_attribute('image_width', image_width)\n",
    "        self._add_to_configs_and_create_as_attribute('image_height', image_height)\n",
    "        self._add_to_configs_and_create_as_attribute('window_size', window_size)\n",
    "\n",
    "\n",
    "    def _add_to_configs_and_create_as_attribute(self, attribute_name: str, value: Any) -> None:\n",
    "        self.configs[attribute_name] = value\n",
    "        setattr(self, attribute_name, self.configs[attribute_name])\n",
    "\n",
    "    \n",
    "    def load_and_parse_file_content(self) -> List[ROI]:\n",
    "        row_cropping_idx, col_cropping_idx = self._get_cropping_indices_to_adjust_for_window_size()\n",
    "        self._add_to_configs_and_create_as_attribute('row_cropping_idx', row_cropping_idx)\n",
    "        self._add_to_configs_and_create_as_attribute('col_cropping_idx', col_cropping_idx)        \n",
    "        grid_row_idxs, grid_col_idxs = self._get_row_col_idxs_of_grid()\n",
    "        grid_row_labels, grid_col_labels = self._get_row_col_labels_for_rois_in_grid()\n",
    "        self._add_to_configs_and_create_as_attribute('max_len_row_label_id', len(str(grid_row_labels[-1])))\n",
    "        self._add_to_configs_and_create_as_attribute('max_len_col_label_id', len(str(grid_col_labels[-1])))\n",
    "        all_rois = []\n",
    "        for row_idx, row_label in zip(grid_row_idxs, grid_row_labels):\n",
    "            for col_idx, col_label in zip(grid_col_idxs, grid_col_labels):\n",
    "                square_corner_row_col_coords = self._get_boundary_row_col_coords_single_square(row_idx, col_idx)\n",
    "                label_id = f'{row_label}/{col_label}'\n",
    "                square_roi = ROI(self.filepath, square_corner_row_col_coords)\n",
    "                square_roi.add_label_id(label_id)\n",
    "                all_rois.append(square_roi)\n",
    "        return all_rois     \n",
    "\n",
    "    \n",
    "    def _get_cropping_indices_to_adjust_for_window_size(self) -> Tuple[int, int]:\n",
    "        row_cropping_index = (self.image_height // self.window_size) * self.window_size\n",
    "        col_cropping_index = (self.image_width // self.window_size) * self.window_size\n",
    "        return row_cropping_index, col_cropping_index\n",
    "        \n",
    "\n",
    "    def _get_row_col_idxs_of_grid(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        grid_row_idxs = np.arange(start = 0, stop = self.row_cropping_idx, step = self.window_size)\n",
    "        grid_col_idxs = np.arange(start = 0, stop = self.col_cropping_idx, step = self.window_size)\n",
    "        return grid_row_idxs, grid_col_idxs\n",
    "\n",
    "\n",
    "    def _get_row_col_labels_for_rois_in_grid(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        grid_row_labels = np.arange(start = 1, stop = self.row_cropping_idx / self.window_size + 1, step = 1, dtype = 'int')\n",
    "        grid_col_labels = np.arange(start = 1, stop = self.col_cropping_idx / self.window_size + 1, step = 1, dtype = 'int')\n",
    "        return grid_row_labels, grid_col_labels\n",
    "                \n",
    "    \n",
    "    def _get_boundary_row_col_coords_single_square(self, upper_left_corner_row_idx: int, upper_left_corner_col_idx: int) -> List[Tuple[(int, int)]]:\n",
    "        upper_left_corner = (upper_left_corner_row_idx, upper_left_corner_col_idx)\n",
    "        upper_right_corner = (upper_left_corner_row_idx, upper_left_corner_col_idx + self.window_size)\n",
    "        lower_right_corner = (upper_left_corner_row_idx + self.window_size, upper_left_corner_col_idx + self.window_size)\n",
    "        lower_left_corner = (upper_left_corner_row_idx + self.window_size, upper_left_corner_col_idx)\n",
    "        return [upper_left_corner, lower_left_corner, lower_right_corner, upper_right_corner, upper_left_corner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RecordingLoader(DataLoader):\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def _get_all_frames(self) -> np.ndarray: \n",
    "        # To be implemented in individual subclasses\n",
    "        # Shape of returned numpy array: [frames, rows, cols, color_channels]\n",
    "        pass\n",
    "\n",
    "\n",
    "    def _load_all_frames(self) -> np.ndarray: \n",
    "        all_frames = self._get_all_frames()\n",
    "        all_frames = self._validate_shape_and_convert_to_grayscale_if_possible(all_frames)\n",
    "        return all_frames\n",
    "\n",
    "\n",
    "    def load_and_parse_file_content(self) -> Recording:\n",
    "        all_frames = self._load_all_frames()\n",
    "        recording = Recording(self.filepath, all_frames)\n",
    "        return recording\n",
    "\n",
    "\n",
    "    def _validate_shape_and_convert_to_grayscale_if_possible(self, zstack: np.ndarray) -> np.ndarray:\n",
    "        self._validate_correct_array_shape(zstack)\n",
    "        if zstack.shape[3] > 1:\n",
    "            if self._check_if_color_channels_are_redunant(zstack) == True:\n",
    "                zstack = self._convert_to_grayscale(zstack)\n",
    "        return zstack\n",
    "\n",
    "\n",
    "    def _validate_correct_array_shape(self, zstack: np.ndarray) -> None:\n",
    "        assert len(zstack.shape) == 4, ('The shape of the zstack numpy array is not correct. It should be a 4 dimensional array, like '\n",
    "                                        f'[frames, rows, cols, color channels]. However, the current shape is: {zstack.shape}.')\n",
    "        assert zstack.shape[3] in [1, 3], ('The color channels of the recording you attempted to load are incorrect. Currently, only single '\n",
    "                                           f'channel or RGB (i.e. 1 or 3 color channels) are supported. However, your data has: {zstack.shape[3]}.')\n",
    "        \n",
    "    \n",
    "    def _check_if_color_channels_are_redunant(self, zstack: np.ndarray) -> bool:\n",
    "        reference_channel_idx = 0\n",
    "        color_channels_are_equal = []\n",
    "        for idx_of_channel_to_compare in range(1, zstack.shape[3]):\n",
    "            if np.array_equal(zstack[:, :, :, reference_channel_idx], zstack[: , :, :, idx_of_channel_to_compare]) == True:\n",
    "                color_channels_are_equal.append(True)\n",
    "            else:\n",
    "                color_channels_are_equal.append(False)\n",
    "                break\n",
    "        return all(color_channels_are_equal)\n",
    "\n",
    "\n",
    "    def _convert_to_grayscale(self, zstack: np.ndarray) -> np.ndarray:\n",
    "        return zstack[:, :, :, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AVILoader(RecordingLoader):\n",
    "\n",
    "    def _get_all_frames(self) -> np.ndarray: \n",
    "        return iio.imread(self.filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ROILoader(DataLoader):\n",
    "\n",
    "    @abstractmethod\n",
    "    def _get_boundary_row_col_coords_for_all_rois_in_source_data(self) -> List[List[Tuple[int, int]]]: \n",
    "        # To be implemented in individual subclasses\n",
    "        # Return a list of Tuples, where each tuple represents one boundary point: (row_coord, col_coord)\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def load_and_parse_file_content(self) -> List[ROI]:\n",
    "        boundary_row_col_coords_for_all_rois = self._get_boundary_row_col_coords_for_all_rois_in_source_data()\n",
    "        all_rois = []\n",
    "        for boundary_row_col_coords_single_roi in boundary_row_col_coords_for_all_rois:\n",
    "            boundary_row_col_coords_single_roi = self._add_first_boundary_point_also_add_end_to_close_roi(boundary_row_col_coords_single_roi)\n",
    "            roi = ROI(self.filepath, boundary_row_col_coords_single_roi)\n",
    "            all_rois.append(roi)\n",
    "        return all_rois\n",
    "\n",
    "\n",
    "    def _add_first_boundary_point_also_add_end_to_close_roi(self, boundary_row_col_coords: List[Tuple[int, int]]) -> List[Tuple[int, int]]:\n",
    "        first_boundary_point_coords = boundary_row_col_coords[0]\n",
    "        boundary_row_col_coords.append(first_boundary_point_coords)\n",
    "        return boundary_row_col_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ImageJROILoader(ROILoader):\n",
    "\n",
    "    \n",
    "    def _get_boundary_row_col_coords_for_all_rois_in_source_data(self) -> List[List[Tuple[int, int]]]:\n",
    "        roi_file_content = roifile.roiread(self.filepath)\n",
    "        if type(roi_file_content) == list:\n",
    "            all_rois = self._extract_boundary_row_col_coords_from_roi_set(roi_file_content)\n",
    "        else:\n",
    "            all_rois = [self._extract_boundary_row_col_coords_from_single_roi(roi_file_content)]\n",
    "        return all_rois\n",
    "\n",
    "\n",
    "    def _extract_boundary_row_col_coords_from_roi_set(self, all_imagej_rois: List[roifile.roifile.ImagejRoi]) -> List[List[Tuple[int, int]]]:\n",
    "        boundary_coords_all_rois = []\n",
    "        for imagej_roi in all_imagej_rois:\n",
    "            boundary_row_col_coords_single_roi = self._extract_boundary_row_col_coords_from_single_roi(imagej_roi)\n",
    "            boundary_coords_all_rois.append(boundary_row_col_coords_single_roi)\n",
    "        return boundary_coords_all_rois\n",
    "    \n",
    "        \n",
    "    def _extract_boundary_row_col_coords_from_single_roi(self, imagej_roi: roifile.roifile.ImagejRoi) -> List[Tuple[int, int]]:\n",
    "        row_coords = imagej_roi.coordinates()[:, 1]\n",
    "        col_coords = imagej_roi.coordinates()[:, 0]\n",
    "        boundary_row_col_coords = list(zip(row_coords, col_coords))\n",
    "        return boundary_row_col_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loader Factories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataLoaderFactory(ABC):\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def supported_extensions_per_data_loader(self) -> Dict[DataLoader, List[str]]:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def all_supported_extensions(self) -> List[str]:\n",
    "        all_supported_extensions = []\n",
    "        for value in self.supported_extensions_per_data_loader.values():\n",
    "            all_supported_extensions += value\n",
    "        return all_supported_extensions\n",
    "\n",
    "    \n",
    "    def get_loader(self, filepath: Path) -> DataLoader:\n",
    "        self._assert_validity_of_filepath(filepath)\n",
    "        data_loader = self._get_loader_for_file_extension(filepath)\n",
    "        return data_loader\n",
    "        \n",
    "\n",
    "    def _assert_validity_of_filepath(self, filepath: Path) -> None:\n",
    "        assert isinstance(filepath, Path), f'filepath must be an instance of a pathlib.Path. However, you passed {filepath}, which is of type {type(filepath)}'\n",
    "        assert filepath.exists(), f'The filepath you provided ({filepath}) does not seem to exist!'\n",
    "        \n",
    "\n",
    "    def _get_loader_for_file_extension(self, filepath: Path) -> DataLoader:\n",
    "        matching_loader = None\n",
    "        for loader_subclass, supported_extensions in self.supported_extensions_per_data_loader.items():\n",
    "            if filepath.suffix in supported_extensions:\n",
    "                matching_loader = loader_subclass(filepath)\n",
    "                break\n",
    "        if matching_loader == None:\n",
    "            raise NotImplementedError('It seems like there is no DataLoader implemented for the specific filetype you´re trying to load - sorry!')\n",
    "        return matching_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RecordingLoaderFactory(DataLoaderFactory):\n",
    "\n",
    "    @property\n",
    "    def supported_extensions_per_data_loader(self) -> Dict[RecordingLoader, List[str]]:\n",
    "        supported_extensions_per_data_loader = {AVILoader: ['.avi']}\n",
    "        return supported_extensions_per_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ROILoaderFactory(DataLoaderFactory):\n",
    "\n",
    "    @property\n",
    "    def supported_extensions_per_data_loader(self) -> Dict[ROILoader, List[str]]:\n",
    "        supported_extensions_per_data_loader = {ImageJROILoader: ['.roi', '.zip']}\n",
    "        return supported_extensions_per_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_filepaths_with_supported_extension_in_dirpath(dirpath: Path, all_supported_extensions: List[str], max_results: Optional[int]=None) -> List[Path]:\n",
    "    all_filepaths_with_supported_extension = []\n",
    "    for elem in dirpath.iterdir():\n",
    "        if elem.is_file() == True:\n",
    "            if elem.suffix in all_supported_extensions:\n",
    "                all_filepaths_with_supported_extension.append(elem)\n",
    "    if type(max_results) == int:\n",
    "        assert len(all_filepaths_with_supported_extension) <= max_results, (\n",
    "            f'There are more than {max_results} file(s) of supported type in {dirpath}, '\n",
    "            f'but only a maximum of {max_results} are allowed. Please remove at least '\n",
    "            f'{len(all_filepaths_with_supported_extension) - max_results} of the following' \n",
    "            f'files and try again: {all_filepaths_with_supported_extension}'\n",
    "        )\n",
    "    return all_filepaths_with_supported_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RecLoaderROILoaderCombinator:\n",
    "\n",
    "        \n",
    "    def __init__(self, dir_path: Path) -> None:\n",
    "        self.dir_path = dir_path\n",
    "\n",
    "    \n",
    "    def get_all_recording_and_roi_loader_combos(self) -> List[Tuple[RecordingLoader, ROILoader]]:\n",
    "        recording_loader = self._get_the_recording_loader()\n",
    "        all_roi_loaders = self._get_all_roi_loaders()\n",
    "        if len(all_roi_loaders) > 0:\n",
    "            rec_roi_loader_combos = [(recording_loader, roi_loader) for roi_loader in all_roi_loaders]\n",
    "        else:\n",
    "            rec_roi_loader_combos = [(recording_loader, None)]\n",
    "        return rec_roi_loader_combos\n",
    "    \n",
    "\n",
    "    def _get_the_recording_loader(self) -> RecordingLoader:\n",
    "        recording_loader_factory = RecordingLoaderFactory()\n",
    "        recording_filepath = get_filepaths_with_supported_extension_in_dirpath(self.dir_path, recording_loader_factory.all_supported_extensions, 1)[0]\n",
    "        recording_loader = recording_loader_factory.get_loader(recording_filepath)\n",
    "        return recording_loader\n",
    "\n",
    "\n",
    "    def _get_all_roi_loaders(self) -> List[ROILoader]:\n",
    "        roi_loader_factory = ROILoaderFactory()\n",
    "        all_roi_filepaths = get_filepaths_with_supported_extension_in_dirpath(self.dir_path, roi_loader_factory.all_supported_extensions)\n",
    "        all_roi_loaders = [roi_loader_factory.get_loader(filepath) for filepath in all_roi_filepaths]\n",
    "        return all_roi_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| hide\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnbdev\u001b[39;00m; nbdev\u001b[38;5;241m.\u001b[39mnbdev_export()\n",
      "File \u001b[0;32m~/anaconda3/envs/na3_nbdev/lib/python3.11/site-packages/fastcore/script.py:112\u001b[0m, in \u001b[0;36mcall_parse.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    111\u001b[0m     mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()\u001b[38;5;241m.\u001b[39mf_back)\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mod: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SCRIPT_INFO\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;129;01mand\u001b[39;00m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m: SCRIPT_INFO\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sys\u001b[38;5;241m.\u001b[39margv)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m: sys\u001b[38;5;241m.\u001b[39margv\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/na3_nbdev/lib/python3.11/site-packages/nbdev/doclinks.py:151\u001b[0m, in \u001b[0;36mnbdev_export\u001b[0;34m(path, procs, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     procs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(nbdev\u001b[38;5;241m.\u001b[39mexport, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m L(procs)]\n\u001b[1;32m    150\u001b[0m files \u001b[38;5;241m=\u001b[39m nbglob(path\u001b[38;5;241m=\u001b[39mpath, as_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39msorted(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files: \u001b[43mnb_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m add_init(get_config()\u001b[38;5;241m.\u001b[39mlib_path)\n\u001b[1;32m    153\u001b[0m _build_modidx()\n",
      "File \u001b[0;32m~/anaconda3/envs/na3_nbdev/lib/python3.11/site-packages/nbdev/export.py:92\u001b[0m, in \u001b[0;36mnb_export\u001b[0;34m(nbname, lib_path, procs, name, mod_maker, debug)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     91\u001b[0m mm \u001b[38;5;241m=\u001b[39m mod_maker(dest\u001b[38;5;241m=\u001b[39mlib_path, name\u001b[38;5;241m=\u001b[39mnm, nb_path\u001b[38;5;241m=\u001b[39mnbname, is_new\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(name) \u001b[38;5;129;01mor\u001b[39;00m mod\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m \u001b[43mmm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcells\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_cells\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlib_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlib_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/na3_nbdev/lib/python3.11/site-packages/nbdev/maker.py:197\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(self, cells, all_cells, lib_path)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib_path: lib_path \u001b[38;5;241m=\u001b[39m get_config()\u001b[38;5;241m.\u001b[39mlib_path\n\u001b[1;32m    196\u001b[0m     mod_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrelpath(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfname\u001b[38;5;241m.\u001b[39mparent, Path(lib_path)\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m--> 197\u001b[0m     \u001b[43m_import2relative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_cells\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_new: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_exists(cells, all_cells)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfname\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/na3_nbdev/lib/python3.11/site-packages/nbdev/maker.py:176\u001b[0m, in \u001b[0;36m_import2relative\u001b[0;34m(cells, lib_name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverts `cells` to use `import2relative` based on `lib_name`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lib_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: lib_name \u001b[38;5;241m=\u001b[39m get_config()\u001b[38;5;241m.\u001b[39mlib_name\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m cells: \u001b[43mcell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport2relative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlib_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/na3_nbdev/lib/python3.11/site-packages/nbdev/maker.py:160\u001b[0m, in \u001b[0;36mimport2relative\u001b[0;34m(cell, libname)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;129m@patch\u001b[39m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport2relative\u001b[39m(cell:NbCell, libname):\n\u001b[0;32m--> 160\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparsed_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlibname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m src: cell\u001b[38;5;241m.\u001b[39mset_source(src)\n",
      "File \u001b[0;32m~/anaconda3/envs/na3_nbdev/lib/python3.11/site-packages/nbdev/maker.py:151\u001b[0m, in \u001b[0;36mupdate_import\u001b[0;34m(source, tree, libname, f)\u001b[0m\n\u001b[1;32m    149\u001b[0m src \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39msplitlines(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imp \u001b[38;5;129;01min\u001b[39;00m imps:\n\u001b[0;32m--> 151\u001b[0m     nmod \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlibname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     lin \u001b[38;5;241m=\u001b[39m imp\u001b[38;5;241m.\u001b[39mlineno\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    153\u001b[0m     sec \u001b[38;5;241m=\u001b[39m src[lin][imp\u001b[38;5;241m.\u001b[39mcol_offset:imp\u001b[38;5;241m.\u001b[39mend_col_offset]\n",
      "File \u001b[0;32m~/anaconda3/envs/na3_nbdev/lib/python3.11/site-packages/nbdev/maker.py:116\u001b[0m, in \u001b[0;36mrelative_import\u001b[0;34m(name, fname, level)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrelative_import\u001b[39m(name, fname, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert a module `name` to a name relative to `fname`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m level\n\u001b[1;32m    117\u001b[0m     sname \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mcommonpath([sname,fname])): \u001b[38;5;28;01mreturn\u001b[39;00m name\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
