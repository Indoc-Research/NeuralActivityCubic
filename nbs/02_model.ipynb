{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model\n",
    "\n",
    "> Defines data and processing structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-tip title = \"New to literate programming?\" appearance=\"simple\" collapse=\"true\"}\n",
    "**Welcome to the inner workings of `neuralactivitycubic`!**\n",
    "\n",
    "This message is here only for you, as we´d like to share some basic information about this piece of research software with you to facilitate your interactions with it. We´re using a literate programming framework called [nbdev](https://nbdev.fast.ai/) for the development, testing, documentation, and dissemination of `neuralactivitycubic`. We believe the concept of rich annotations and usage examples directly intermixed with the source code (read more about the concept of literate programming for instance [here](https://blog.esciencecenter.nl/literate-programming-in-science-1669094541a7)) holds great value and potential, especially in the context of research software, as it makes it easier for others to understand, (re-)use, and ideally even to adapt or contribute to your code. That being said, some things in here might look a bit confusing to you - conversely especially if you are an experienced developer used to \"regular\" source code. \n",
    "\n",
    "For instance, you´ll regularly find the implementation of a class, like the `Model` here, interrupted by markdown text and maybe even some addtional code cells that serve as usage examples or even represent the implementation of tests, only for the subsequent class methods to continue in code cells below, literally patched to the class using the `@patch` decorator. Just be aware that this may not meet your expectations of what conventional source code \"should\" look like and maybe you can discover some valuable takeaway for you along the way, too!\n",
    "\n",
    "One final note before you head on, though: we are ourselves still experimenting a lot with this concept and how it can be used to best effect and are more than happy to engage in discussion or to hear your feedback on this topic. Feel free to drop us a message via GitHub!\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everybody needs some help - and we´re standing on the shoulders of some giants here. Let´s start by importing all dependencies we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "# Actual functional dependencies:\n",
    "# external:\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from matplotlib.pyplot import show\n",
    "import ipywidgets as w\n",
    "import multiprocessing\n",
    "from fastcore.basics import patch\n",
    "import gc\n",
    "\n",
    "# and internal:\n",
    "from neuralactivitycubic.datamodels import Config\n",
    "from neuralactivitycubic.processing import AnalysisJob\n",
    "from neuralactivitycubic.input import RecordingLoaderFactory, ROILoaderFactory, RecordingLoader, ROILoader, get_filepaths_with_supported_extension_in_dirpath, FocusAreaPathRestrictions\n",
    "\n",
    "# Finally, some dependencies regarding type hints:\n",
    "from typing import Callable\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.axes._axes import Axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let´s get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "class Logger:\n",
    "\n",
    "    \"\"\"\n",
    "    A simple logging utility class that captures log messages with UTC timestamps,\n",
    "    allows retrieval and clearing of logs, and supports saving them to a file.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logs = []\n",
    "\n",
    "    def add_new_log(self, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Add a new log message with a UTC timestamp prefix. \n",
    "        The timestamp is formatted as 'dd-mm-yy HH:MM:SS.ffffff (UTC)'.\n",
    "        \"\"\"\n",
    "        time_prefix_in_utc = datetime.now(timezone.utc).strftime('%d-%m-%y %H:%M:%S.%f')\n",
    "        self.logs.append(f'{time_prefix_in_utc} (UTC): {message}')\n",
    "        print(f'{time_prefix_in_utc} (UTC): {message}')\n",
    "\n",
    "    def get_logs(self) -> list[str]:\n",
    "        return self.logs\n",
    "\n",
    "    def clear_logs(self) -> None:\n",
    "        self.logs = []\n",
    "\n",
    "    def save_current_logs(self, save_dir: Path) -> None:\n",
    "        filepath = save_dir.joinpath('logs.txt')\n",
    "        with open(filepath , 'w+') as logs_file:\n",
    "            for log_message in self.logs:\n",
    "                logs_file.write(f'{log_message}\\n')\n",
    "        print(f'Logs saved to {filepath}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is the `Model`, which is at the absolute core of `neuralactivitycubic`. After initialization of a `Model` object, there are only two more calls you need to make to run a fullblown analysis with `na3`. You can see this in the implementation of the `api.run_analysis()` wrapper, which actually also represents the way we intend you to use `na3` programmatically.\n",
    "\n",
    "Therefore, we´ll instead continue gradually diving deeper into the inner workings of this class and let you in on our thoughts, reasons, and intentions of the different aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, \n",
    "                 config: Config | str\n",
    "                ) -> None:\n",
    "        self.num_processes = multiprocessing.cpu_count()\n",
    "        self.analysis_job_queue = []\n",
    "        self.result_directories = []\n",
    "        self.logs = Logger()\n",
    "        if isinstance(config, str):\n",
    "            config = Config(data_source_path=config)\n",
    "        self.config = config\n",
    "        self.nwb_metadata = None\n",
    "        self.gui_enabled = False\n",
    "        self.callback_view_update_infos = None\n",
    "        self.callback_view_show_output_screen = None\n",
    "        self.view_output = None\n",
    "        self.pixel_conversion = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, let´s actually get started with those two methods that run the fullblown analysis and also represent the highest level functions in the `Model`. They are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "\n",
    "@patch\n",
    "def create_analysis_jobs(self: Model\n",
    "                        ) -> None:\n",
    "    self._ensure_data_from_previous_jobs_was_removed()\n",
    "    self.add_info_to_logs('Basic configurations for data import validated. Starting creation of analysis job(s)...', True)\n",
    "    if self.config.batch_mode:\n",
    "        all_subdir_paths_with_rec_file = self._get_all_subdir_paths_with_rec_file(self.config.data_source_path)\n",
    "        all_subdir_paths_with_rec_file.sort()\n",
    "        for idx, subdir_path in enumerate(all_subdir_paths_with_rec_file):\n",
    "            if self.config.results_filepath:\n",
    "                result_path = self.config.results_filepath / subdir_path.name\n",
    "            else:\n",
    "                result_path = subdir_path\n",
    "            self._create_analysis_jobs_for_single_rec(subdir_path, result_path)\n",
    "    else:\n",
    "        self._create_analysis_jobs_for_single_rec()\n",
    "    self.add_info_to_logs('All job creation(s) completed.', True, 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "\n",
    "@patch\n",
    "def run_analysis(self: Model\n",
    "                ) -> None:\n",
    "    self._display_configs()\n",
    "    self.add_info_to_logs('Starting analysis...', True)\n",
    "    for job_idx in range(len(self.analysis_job_queue)):\n",
    "        analysis_job = self.analysis_job_queue.pop(0)\n",
    "        self.add_info_to_logs(f'Starting to process analysis job with index #{job_idx}.')\n",
    "        analysis_job.run_analysis(self.config)\n",
    "        self.add_info_to_logs(f'Analysis successfully completed. Continue with creation of results.. ')\n",
    "        analysis_job.create_results(self.config, self.nwb_metadata)\n",
    "        self.add_info_to_logs(f'Results successfully created at: {analysis_job.results_dir_path}')\n",
    "        if self.gui_enabled:\n",
    "            self.callback_view_show_output_screen()\n",
    "            with self.view_output:\n",
    "                activity_overview_fig = analysis_job.activity_overview_plot[0]\n",
    "                activity_overview_fig.set_figheight(400 * self.pixel_conversion)\n",
    "                activity_overview_fig.tight_layout()\n",
    "                show(activity_overview_fig)\n",
    "        self._save_user_settings_as_json(analysis_job)\n",
    "        self.result_directories.append(analysis_job.results_dir_path)\n",
    "        self.add_info_to_logs('Updating all log files to contain all logs as final step. All valid logs files will end with this message.')\n",
    "        self.logs.save_current_logs(analysis_job.results_dir_path)\n",
    "    else:\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of them come with a bunch of private methods that are not intended to be called from the outside. The following private methods do the heavy lifting when it comes to the creation of analysis jobs. Since `na3` offers batch mode processing, we have to deal with complex recursive browsing of directories and subdirectories, checking for files that can be handled by `na3` using the various `RecordingLoader` and `ROILoader` or rather their respective factories (checkout the `03_input.ipynb` notebook for implementation) that definitely takes a toll on readability. If you´re nonetheless brave enough, feel free to take a look of how we addressed this challenge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "@patch\n",
    "def _ensure_data_from_previous_jobs_was_removed(self: Model\n",
    "                                               ) -> None:\n",
    "    self.add_info_to_logs('Loading of new source data. All previously created jobs & logs will be deleted.', True)\n",
    "    self.analysis_job_queue = []\n",
    "    self.logs.clear_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "@patch\n",
    "#@staticmethod\n",
    "def _get_all_subdir_paths_with_rec_file(self: Model, \n",
    "                                        top_level_dir_path: Path\n",
    "                                       ) -> list[Path]:\n",
    "    rec_loader_factory = RecordingLoaderFactory()\n",
    "    supported_extensions_for_recordings = rec_loader_factory.all_supported_extensions\n",
    "    all_subdir_paths_that_contain_a_supported_recording_file = []\n",
    "    for elem in top_level_dir_path.iterdir():\n",
    "        if not elem.name.startswith('.'):\n",
    "            if elem.is_dir():\n",
    "                supported_recording_filepaths = [elem_2 for elem_2 in elem.iterdir() if elem_2.suffix in supported_extensions_for_recordings]\n",
    "                if len(supported_recording_filepaths) > 0:\n",
    "                    all_subdir_paths_that_contain_a_supported_recording_file.append(elem)\n",
    "    return all_subdir_paths_that_contain_a_supported_recording_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "@patch\n",
    "def _create_analysis_jobs_for_single_rec(self: Model, \n",
    "                                         recording_path: Path = None,\n",
    "                                         result_path: Path = None\n",
    "                                        ) -> None:\n",
    "    if recording_path is None:\n",
    "        if self.config.recording_filepath:\n",
    "            recording_path = self.config.recording_filepath\n",
    "        else:\n",
    "            recording_path = self.config.data_source_path\n",
    "    self.add_info_to_logs(f'Starting with Job creation(s) for {str(recording_path)}', True)\n",
    "    recording_loader = self._get_recording_loader(recording_path)\n",
    "\n",
    "\n",
    "    if self.config.roi_filepath:\n",
    "        roi_filepath = self.config.roi_filepath\n",
    "    else:\n",
    "        roi_filepath = recording_loader.filepath.parent\n",
    "\n",
    "    if self.config.roi_mode == 'file':\n",
    "        roi_loaders = self._get_all_roi_loaders(roi_filepath)\n",
    "    else:\n",
    "        roi_loaders = None\n",
    "\n",
    "    if self.config.focus_area_filepath:\n",
    "        focus_area_filepath = self.config.focus_area_filepath\n",
    "    else:\n",
    "        focus_area_filepath = recording_loader.filepath.parent\n",
    "\n",
    "    if result_path is None:\n",
    "        if self.config.results_filepath:\n",
    "            result_path = self.config.results_filepath\n",
    "        else:\n",
    "            result_path = recording_loader.filepath.parent\n",
    "\n",
    "    if self.config.focus_area_enabled:\n",
    "        focus_area_dir_path = self._get_focus_area_dir_path(focus_area_filepath)\n",
    "        if focus_area_dir_path is None:\n",
    "            analysis_job = self._create_single_analysis_job(recording_loader, roi_loaders, result_filepath=result_path)\n",
    "            self.analysis_job_queue.append(analysis_job)\n",
    "            self.add_info_to_logs(f'Successfully created a single job for {focus_area_filepath} at queue position: #{len(self.analysis_job_queue)}.', True)\n",
    "        else:\n",
    "            all_focus_area_loaders = self._get_all_roi_loaders(focus_area_dir_path)\n",
    "            assert len(all_focus_area_loaders) > 0, f'Focus Area analysis enabled, but no focus area ROIs could be found. Please revisit your source data and retry!'\n",
    "            for idx, focus_area_loader in enumerate(all_focus_area_loaders):\n",
    "                if result_path is None:\n",
    "                    if self.config.results_filepath:\n",
    "                        result_path = self.config.results_filepath / focus_area_loader.filepath.stem\n",
    "                analysis_job_with_focus_area = self._create_single_analysis_job(recording_loader, roi_loaders, focus_area_loader, result_filepath=result_path)\n",
    "                self.analysis_job_queue.append(analysis_job_with_focus_area)\n",
    "                job_creation_message = (f'Successfully created {idx + 1} out of {len(all_focus_area_loaders)} job(s) for {recording_path} '\n",
    "                                        f'at queue position: #{len(self.analysis_job_queue)}.')\n",
    "                self.add_info_to_logs(job_creation_message, True)\n",
    "    else:\n",
    "        analysis_job = self._create_single_analysis_job(recording_loader, roi_loaders, result_filepath=result_path)\n",
    "        self.analysis_job_queue.append(analysis_job)\n",
    "        self.add_info_to_logs(f'Successfully created a single job for {recording_path} at queue position: #{len(self.analysis_job_queue)}.', True)\n",
    "    self.add_info_to_logs(f'Finished Job creation(s) for {recording_path}!', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "@patch\n",
    "def _get_recording_loader(self: Model, \n",
    "                          source_path: Path\n",
    "                         ) -> RecordingLoader:\n",
    "    rec_loader_factory = RecordingLoaderFactory()\n",
    "    if source_path.is_dir():\n",
    "        self.add_info_to_logs(f'Looking for a valid recording file in {source_path}...', True)\n",
    "        valid_filepaths = get_filepaths_with_supported_extension_in_dirpath(source_path, rec_loader_factory.all_supported_extensions, 1)\n",
    "        if len(valid_filepaths) == 0:\n",
    "            self.add_info_to_logs(f'Could not find any recording files of supported type at {source_path}!', True)\n",
    "        elif len(valid_filepaths) >  1:\n",
    "            filepath = valid_filepaths[0]\n",
    "            too_many_files_message = (f'Found more than a single recording file of supported type at {source_path}, i.e.: {valid_filepaths}. '\n",
    "                                      f'However, only a single file was expected. NA3 continues with {filepath} and will ignore the other files.')\n",
    "            self.add_info_to_logs(too_many_files_message, True)\n",
    "        else:\n",
    "            filepath = valid_filepaths[0]\n",
    "            self.add_info_to_logs(f'Found recording file of supported type at: {filepath}.', True)\n",
    "    else:\n",
    "        filepath = source_path\n",
    "        self.add_info_to_logs(f'Found recording file of supported type at: {filepath}.', True)\n",
    "    recording_loader = rec_loader_factory.get_loader(filepath)\n",
    "    return recording_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "@patch\n",
    "def _get_all_roi_loaders(self: Model, \n",
    "                         data_source_path: Path\n",
    "                        ) -> list[ROILoader]:\n",
    "    assert data_source_path.is_dir(), f'You must provide a directory as source data when using ROI mode or enabling Focus Areas. Please revisit your input data and retry.'\n",
    "    roi_loader_factory = ROILoaderFactory()\n",
    "    all_filepaths_with_supported_filetype_extensions = get_filepaths_with_supported_extension_in_dirpath(data_source_path, roi_loader_factory.all_supported_extensions)\n",
    "    all_roi_loaders = [roi_loader_factory.get_loader(roi_filepath) for roi_filepath in all_filepaths_with_supported_filetype_extensions]\n",
    "    return all_roi_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "@patch\n",
    "def _get_focus_area_dir_path(self: Model, \n",
    "                             source_path: Path\n",
    "                            ) -> Path:\n",
    "    focus_area_path_restrictions = FocusAreaPathRestrictions()\n",
    "    supported_dir_names = focus_area_path_restrictions.supported_dir_names\n",
    "    if source_path.is_dir():\n",
    "        source_dir_path = source_path\n",
    "    else:\n",
    "        source_dir_path = source_path.parent\n",
    "    dirs_with_valid_name = [elem for elem in source_dir_path.iterdir() if (elem.name in supported_dir_names) & (elem.is_dir() == True)]\n",
    "    if len(dirs_with_valid_name) == 0:\n",
    "        no_dir_found_message = (f'You enabled Focus Area but a correspondingly named directory could not be found in {source_dir_path}. '\n",
    "                                f'Please use one of the following for the name of the directory that contains the Focus Area ROIs: {supported_dir_names}. '\n",
    "                                'In absence of such a directory, analysis is continued without using the Focus Area mode for this data.')\n",
    "        self.add_info_to_logs(no_dir_found_message, True)\n",
    "        focus_area_dir_path = None\n",
    "    elif len(dirs_with_valid_name) > 1:\n",
    "        too_many_dirs = (f'More than a single Focus Area directory was found in the following parent directory: {source_dir_path}, i.e.: '\n",
    "                         f'{dirs_with_valid_name}. However, only the use of a single one that contains all your Focus Area ROIS is '\n",
    "                         f'currently supported. {dirs_with_valid_name[0]} will be used for this analysis, while the other(s): {dirs_with_valid_name[1:]} '\n",
    "                         'will be ignored to continue processing.')\n",
    "        self.add_info_to_logs(too_many_dirs, True)\n",
    "        focus_area_dir_path = dirs_with_valid_name[0]\n",
    "    else:\n",
    "        focus_area_dir_path = dirs_with_valid_name[0]\n",
    "    return focus_area_dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "@patch\n",
    "def _create_single_analysis_job(self: Model,\n",
    "                                recording_loader: RecordingLoader,\n",
    "                                roi_loaders: list[ROILoader] | None,\n",
    "                                focus_area_loader: ROILoader = None,\n",
    "                                result_filepath: Path = None\n",
    "                               ) -> AnalysisJob:\n",
    "    data_loaders = {'recording': recording_loader}\n",
    "    if roi_loaders is not None:\n",
    "        data_loaders['rois'] = roi_loaders\n",
    "    if focus_area_loader is not None:\n",
    "        data_loaders['focus_area'] = focus_area_loader\n",
    "    return AnalysisJob(self.num_processes, data_loaders, result_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The private methods used by `Model.run_analysis()` are less complex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "@patch\n",
    "def _display_configs(self: Model\n",
    "                    ) -> None:\n",
    "    self.add_info_to_logs('Configurations for Analysis Settings and Result Creation validated successfully.', True)\n",
    "    self.add_info_to_logs(f'Analysis Settings are:')\n",
    "    for line in self.config.display_all_attributes():\n",
    "        self.add_info_to_logs(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "@patch\n",
    "def _save_user_settings_as_json(self: Model, \n",
    "                                analysis_job: AnalysisJob\n",
    "                               ) -> None:\n",
    "    filepath = analysis_job.results_dir_path.joinpath('user_settings.json')\n",
    "    self.config.recording_filepath = analysis_job.recording.filepath\n",
    "    if analysis_job.focus_area_enabled:\n",
    "        self.config.focus_area_filepath = analysis_job.focus_area.filepath\n",
    "    else:\n",
    "        self.config.focus_area_filepath = None\n",
    "    if analysis_job.rois_source == 'file':\n",
    "        self.config.roi_filepath = [roi.filepath for roi in analysis_job.all_rois]\n",
    "    with open(filepath, 'w+') as user_settings_json:\n",
    "        user_settings_json.write(self.config.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, you may have already spotted that both the `Model.run_analysis()` as well as some of the private methods in this class are using the `Model.add_info_to_logs()` method that handles rendering of logs, leveraging the `Logger` class implemented at the top of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "@patch\n",
    "def add_info_to_logs(self: Model, \n",
    "                     message: str, \n",
    "                     display_in_gui: bool = False, \n",
    "                     progress_in_percent: float | None = None\n",
    "                    ) -> None:\n",
    "    self.logs.add_new_log(message)\n",
    "    if (display_in_gui == True) and (self.gui_enabled == True): \n",
    "        self.callback_view_update_infos(message, progress_in_percent)\n",
    "\n",
    "\n",
    "    def add_info_to_logs(self, message: str, display_in_gui: bool = False, progress_in_percent: float | None = None) -> None:\n",
    "        self.logs.add_new_log(message)\n",
    "        if (display_in_gui == True) and (self.gui_enabled == True): \n",
    "            self.callback_view_update_infos(message, progress_in_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the text output, the `Model` can also produce some visual outputs. This is particularly of relevance, when the `Model` is connected to the graphical user interface (GUI) of `neuralactivitycubic`. In that case, the output it generates (e.g. logs, plots, or figures) are rendered in the intended widgets. Since we´re following the [Model-View-Controller](https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller) pattern, this connection between the *model* (literally this `Model` class) and the *view* (the GUI implemented in `01_view.ipynb`) is established via the *controller* (the `App` implemented in `00_controller.ipynb`) by calling the following two public methods: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "@patch\n",
    "def setup_connection_to_update_infos_in_view(self: Model, \n",
    "                                             update_infos: Callable\n",
    "                                            ) -> None:\n",
    "    \"\"\" Allows to configure the widget in the GUI that is used to display the logs. \"\"\"\n",
    "    self.callback_view_update_infos = update_infos\n",
    "    self.gui_enabled = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "@patch\n",
    "def setup_connection_to_display_results(self: Model, \n",
    "                                        show_output_screen: Callable, \n",
    "                                        output: w.Output, \n",
    "                                        pixel_conversion: float\n",
    "                                       ) -> None:\n",
    "    \"\"\" Allows to configure the widget in the GUI that is used to display images, plots, and figures. \"\"\"\n",
    "    self.callback_view_show_output_screen = show_output_screen\n",
    "    self.view_output = output\n",
    "    self.pixel_conversion = pixel_conversion\n",
    "    self.gui_enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this scenario - i.e. usage of `na3` via the GUI - there is also one final method implemented in the `Model` that allows the user to preview how the configured grid size looks like on the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "@patch\n",
    "def preview_window_size(self: Model, \n",
    "                        grid_size\n",
    "                       ) -> tuple[Figure, Axes]:\n",
    "    job_for_preview = self.analysis_job_queue[0]\n",
    "    preview_fig, preview_ax = job_for_preview.preview_window_size(grid_size)\n",
    "    return preview_fig, preview_ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show_doc(Model.preview_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew - that was it! This is the end of the implementation of the `Model` class. Below you find the test cases we implemented with respect to the implementations in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "import os\n",
    "from re import compile\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "from neuralactivitycubic.view import WidgetsInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filepath = Path('../test_data/00')\n",
    "\n",
    "test00_filepath = Path('../test_data/00')\n",
    "test01_filepath = Path('../test_data/01')\n",
    "parent_test_filepath = Path('../test_data')\n",
    "example_results_dir = Path('../test_data/00/example_test_results_for_spiking_neuron')\n",
    "results_filepath = Path('../test_data/00/results_directory')\n",
    "# we have to split results by own directories due to concurrency issues\n",
    "results_case01_filepath = Path('../test_data/results/case_01/')\n",
    "results_case02_filepath = Path('../test_data/results/case_02/')\n",
    "results_case03_filepath = Path('../test_data/results/case_03/')\n",
    "results_case04_filepath = Path('../test_data/results/case_04/')\n",
    "results_case05_filepath = Path('../test_data/results/case_05/')\n",
    "results_case06_filepath = Path('../test_data/results/case_06/')\n",
    "\n",
    "def test_correct_model_run():\n",
    "    correct_config = WidgetsInterface().export_user_settings()\n",
    "    correct_config.data_source_path = test00_filepath / 'spiking_neuron.avi'\n",
    "    correct_config.save_single_trace_results = True\n",
    "    model = Model(correct_config)\n",
    "    model.create_analysis_jobs()\n",
    "    model.run_analysis()\n",
    "    return model.result_directories\n",
    "\n",
    "def test_correct_model_run_with_custom_results_dir():\n",
    "    correct_config = WidgetsInterface().export_user_settings()\n",
    "    correct_config.data_source_path = test00_filepath / 'spiking_neuron.avi'\n",
    "    correct_config.results_filepath = results_filepath\n",
    "    model = Model(correct_config)\n",
    "    model.create_analysis_jobs()\n",
    "    model.run_analysis()\n",
    "    return correct_config.results_filepath\n",
    "\n",
    "# tests with different modes of running analysis\n",
    "\n",
    "def test_run_grid_focus_mode():\n",
    "    \"\"\"\n",
    "    Test run_analysis function with focus area enabled.\n",
    "    \"\"\"\n",
    "    grid_focus_mode_config = WidgetsInterface().export_user_settings()\n",
    "    grid_focus_mode_config.data_source_path = test01_filepath\n",
    "    grid_focus_mode_config.focus_area_enabled = True\n",
    "    grid_focus_mode_config.results_filepath = results_case01_filepath\n",
    "    model = Model(grid_focus_mode_config)\n",
    "    model.create_analysis_jobs()\n",
    "    model.run_analysis()\n",
    "\n",
    "    return grid_focus_mode_config.results_filepath\n",
    "\n",
    "def test_run_file_focus_mode():\n",
    "    \"\"\"\n",
    "    Test run_analysis function with focus area enabled.\n",
    "    \"\"\"\n",
    "    file_focus_mode_config = WidgetsInterface().export_user_settings()\n",
    "    file_focus_mode_config.data_source_path = test01_filepath\n",
    "    file_focus_mode_config.focus_area_enabled = True\n",
    "    file_focus_mode_config.roi_mode = 'file'\n",
    "    file_focus_mode_config.results_filepath = results_case01_filepath\n",
    "    model = Model(file_focus_mode_config)\n",
    "    model.create_analysis_jobs()\n",
    "    model.run_analysis()\n",
    "\n",
    "    return file_focus_mode_config.results_filepath\n",
    "\n",
    "def test_run_grid_batch_mode():\n",
    "    \"\"\"\n",
    "    Test run_analysis function with batch mode enabled.\n",
    "    \"\"\"\n",
    "    grid_batch_mode_config = WidgetsInterface().export_user_settings()\n",
    "    grid_batch_mode_config.data_source_path = parent_test_filepath\n",
    "    grid_batch_mode_config.batch_mode = True\n",
    "    grid_batch_mode_config.results_filepath = results_case02_filepath\n",
    "    model = Model(grid_batch_mode_config)\n",
    "    model.create_analysis_jobs()\n",
    "    model.run_analysis()\n",
    "\n",
    "    return grid_batch_mode_config.results_filepath\n",
    "\n",
    "def test_run_file_batch_mode():\n",
    "    \"\"\"\n",
    "    Test run_analysis function with batch mode enabled.\n",
    "    \"\"\"\n",
    "    file_batch_mode_config = WidgetsInterface().export_user_settings()\n",
    "    file_batch_mode_config.data_source_path = parent_test_filepath\n",
    "    file_batch_mode_config.batch_mode = True\n",
    "    file_batch_mode_config.roi_mode = 'file'\n",
    "    file_batch_mode_config.results_filepath = results_case02_filepath\n",
    "    model = Model(file_batch_mode_config)\n",
    "    model.create_analysis_jobs()\n",
    "    model.run_analysis()\n",
    "\n",
    "    return file_batch_mode_config.results_filepath\n",
    "\n",
    "def test_run_grid_focus_batch_mode():\n",
    "    \"\"\"\n",
    "    Test run_analysis function with focus and batch mode enabled.\n",
    "    \"\"\"\n",
    "    grid_focus_batch_mode_config = WidgetsInterface().export_user_settings()\n",
    "    grid_focus_batch_mode_config.data_source_path = parent_test_filepath\n",
    "    grid_focus_batch_mode_config.batch_mode = True\n",
    "    grid_focus_batch_mode_config.focus_area_enabled = True\n",
    "    grid_focus_batch_mode_config.results_filepath = results_case03_filepath\n",
    "    model = Model(grid_focus_batch_mode_config)\n",
    "    model.create_analysis_jobs()\n",
    "    model.run_analysis()\n",
    "\n",
    "    return grid_focus_batch_mode_config.results_filepath\n",
    "\n",
    "def test_run_file_focus_batch_mode():\n",
    "    \"\"\"\n",
    "    Test run_analysis function with focus and batch mode enabled.\n",
    "    \"\"\"\n",
    "    file_focus_batch_mode_config = WidgetsInterface().export_user_settings()\n",
    "    file_focus_batch_mode_config.data_source_path = parent_test_filepath\n",
    "    file_focus_batch_mode_config.batch_mode = True\n",
    "    file_focus_batch_mode_config.focus_area_enabled = True\n",
    "    file_focus_batch_mode_config.roi_mode = 'file'\n",
    "    file_focus_batch_mode_config.results_filepath = results_case03_filepath\n",
    "    model = Model(file_focus_batch_mode_config)\n",
    "    model.create_analysis_jobs()\n",
    "    model.run_analysis()\n",
    "\n",
    "    return file_focus_batch_mode_config.results_filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_csv_files(relative_filepath_to_csv: str, results_dir: Path) -> bool:\n",
    "    filepath = results_dir / relative_filepath_to_csv\n",
    "    # confirm results have been created:\n",
    "    if not filepath.is_file():\n",
    "        return False\n",
    "    # confirm computational consistency of results, while allowing minor numerical tolerance\n",
    "    df_test = pd.read_csv(filepath)\n",
    "    df_validation = pd.read_csv(example_results_dir / relative_filepath_to_csv)\n",
    "    if assert_frame_equal(df_test, df_validation) is not None:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def test_all_peak_results(results_dir):\n",
    "    return _test_csv_files('all_peak_results.csv', results_dir)\n",
    "\n",
    "def test_amplitude_and_df_over_f_results(results_dir):\n",
    "    return _test_csv_files('Amplitude_and_dF_over_F_results.csv', results_dir)\n",
    "\n",
    "def test_auc_results(results_dir):\n",
    "    return _test_csv_files('AUC_results.csv', results_dir)\n",
    "\n",
    "def test_variance_area_results(results_dir):\n",
    "    return _test_csv_files('Variance_area_results.csv', results_dir)\n",
    "\n",
    "def test_representative_single_trace_results(results_dir):\n",
    "    return _test_csv_files('single_traces/data_of_ROI_7-10.csv', results_dir)\n",
    "\n",
    "def test_activity_overview_png(results_dir):\n",
    "    filepath = results_dir / 'activity_overview.png'\n",
    "    return filepath.is_file()\n",
    "\n",
    "def test_roi_label_ids_overview_png(results_dir):\n",
    "    filepath = results_dir / 'ROI_label_IDs_overview.png'\n",
    "    return filepath.is_file()\n",
    "\n",
    "def test_individual_traces_with_identified_events_pdf(results_dir):\n",
    "    filepath = results_dir / 'Individual_traces_with_identified_events.pdf'\n",
    "    return filepath.is_file()\n",
    "\n",
    "def test_logs_txt(results_dir):\n",
    "    filepath = results_dir / 'logs.txt'\n",
    "    return filepath.is_file()\n",
    "\n",
    "def test_user_settings_json(results_dir):\n",
    "    filepath = results_dir / 'user_settings.json'\n",
    "    return filepath.is_file()\n",
    "\n",
    "def test_nwb_export(results_dir):\n",
    "    filepath = results_dir / 'autogenerated_nwb_file.nwb'\n",
    "\n",
    "def test_all_correct_files_created(results_dir: Path, test_csv: bool = True, single_trace: bool = False) -> bool:\n",
    "    \"\"\"\n",
    "    Check if all expected files have been created in the results directory.\n",
    "    \"\"\"\n",
    "    # confirm all csv files have been created and are correct:\n",
    "    if test_csv:\n",
    "        assert test_all_peak_results(results_dir), 'There is an issue with the \"all_peak_results.csv\" file!'\n",
    "        assert test_amplitude_and_df_over_f_results(results_dir)\n",
    "        assert test_auc_results(results_dir)\n",
    "        assert test_variance_area_results(results_dir)\n",
    "        if single_trace:\n",
    "            assert test_representative_single_trace_results(results_dir)\n",
    "\n",
    "    # confirm all other result files have been created:\n",
    "    assert test_activity_overview_png(results_dir)\n",
    "    assert test_roi_label_ids_overview_png(results_dir)\n",
    "    assert test_logs_txt(results_dir)\n",
    "    assert test_user_settings_json(results_dir)\n",
    "    if single_trace:\n",
    "        assert test_individual_traces_with_identified_events_pdf(results_dir)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def find_directories_after_test(base_path):\n",
    "    \"\"\"\n",
    "    Find directories after test with timestamps.\n",
    "    \"\"\"\n",
    "    pattern = compile(r'\\d{4}_\\d{2}_\\d{2}_\\d{2}-\\d{2}-\\d{2}_.+')\n",
    "\n",
    "    matching_dirs = [\n",
    "        str(base_path) + d for d in os.listdir(base_path)\n",
    "        if os.path.isdir(os.path.join(base_path, d)) and pattern.fullmatch(d)\n",
    "    ]\n",
    "\n",
    "    return matching_dirs\n",
    "\n",
    "def delete_directories_after_test(paths_list):\n",
    "    \"\"\"\n",
    "    Delete directories after test.\n",
    "    \"\"\"\n",
    "    for res_dir in find_directories_after_test(paths_list):\n",
    "        rmtree(res_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that model can be executed:\n",
    "result_directories = test_correct_model_run()\n",
    "\n",
    "for directory in result_directories:\n",
    "    assert directory.exists()\n",
    "    assert test_all_correct_files_created(directory)\n",
    "    # cleanup\n",
    "    rmtree(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that model can be executed with custom result directory:\n",
    "results_directory = test_correct_model_run_with_custom_results_dir()\n",
    "\n",
    "assert results_directory.exists()\n",
    "# only one directory with analysis files should be created, as there are only one focus area:\n",
    "assert len(list(results_directory.iterdir())) == 1\n",
    "\n",
    "for directory in results_directory.iterdir():\n",
    "    assert test_all_correct_files_created(directory)\n",
    "\n",
    "# cleanup\n",
    "rmtree(results_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that model can be executed with focus mode:\n",
    "results_directory = test_run_grid_focus_mode()\n",
    "\n",
    "assert results_directory.exists()\n",
    "\n",
    "# only one directory should be created, as there are only one focus area:\n",
    "assert len(list(results_directory.iterdir())) == 2\n",
    "for directory in results_directory.iterdir():\n",
    "    assert test_all_correct_files_created(directory, test_csv=False)\n",
    "\n",
    "# cleanup\n",
    "rmtree(results_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that model can be executed with batch mode:\n",
    "results_directory = test_run_grid_batch_mode()\n",
    "\n",
    "assert results_directory.exists()\n",
    "\n",
    "assert len(list(results_directory.iterdir())) == 3\n",
    "for directory in results_directory.iterdir():\n",
    "    for subdirectory in directory.iterdir():\n",
    "        assert test_all_correct_files_created(subdirectory, test_csv=False)\n",
    "\n",
    "# cleanup\n",
    "rmtree(results_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that model can be executed with batch and focus mode:\n",
    "results_directory = test_run_grid_focus_batch_mode()\n",
    "\n",
    "assert results_directory.exists()\n",
    "\n",
    "assert len(list(results_directory.iterdir())) == 3\n",
    "for directory in results_directory.iterdir():\n",
    "    # test case with multiple focus areas\n",
    "    if '01' in directory.name:\n",
    "        assert len(list(directory.iterdir())) == 2\n",
    "    for subdirectory in directory.iterdir():\n",
    "        assert test_all_correct_files_created(subdirectory, test_csv=False)\n",
    "\n",
    "# cleanup\n",
    "rmtree(results_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that model can be executed with focus mode:\n",
    "results_directory = test_run_file_focus_mode()\n",
    "\n",
    "assert results_directory.exists()\n",
    "\n",
    "# only one directory should be created, as there are only one focus area:\n",
    "assert len(list(results_directory.iterdir())) == 2\n",
    "for directory in results_directory.iterdir():\n",
    "    assert test_all_correct_files_created(directory, test_csv=False)\n",
    "\n",
    "# cleanup\n",
    "rmtree(results_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that model can be executed with batch mode:\n",
    "results_directory = test_run_file_batch_mode()\n",
    "\n",
    "assert results_directory.exists()\n",
    "\n",
    "assert len(list(results_directory.iterdir())) == 3\n",
    "for directory in results_directory.iterdir():\n",
    "    for subdirectory in directory.iterdir():\n",
    "        assert test_all_correct_files_created(subdirectory, test_csv=False)\n",
    "\n",
    "# cleanup\n",
    "rmtree(results_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that model can be executed with batch and focus mode:\n",
    "results_directory = test_run_file_focus_batch_mode()\n",
    "\n",
    "assert results_directory.exists()\n",
    "\n",
    "assert len(list(results_directory.iterdir())) == 3\n",
    "for directory in results_directory.iterdir():\n",
    "    # test case with multiple focus areas\n",
    "    if '01' in directory.name:\n",
    "        assert len(list(directory.iterdir())) == 2\n",
    "    for subdirectory in directory.iterdir():\n",
    "        assert test_all_correct_files_created(subdirectory, test_csv=False)\n",
    "\n",
    "# cleanup\n",
    "rmtree(results_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
