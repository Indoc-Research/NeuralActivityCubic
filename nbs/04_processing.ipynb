{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# processing\n",
    "\n",
    "> Defines the structure of individual analysis jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.axes._axes import Axes \n",
    "from datetime import datetime\n",
    "from shapely import get_coordinates\n",
    "\n",
    "\n",
    "from dateutil.tz import tzlocal\n",
    "from uuid import uuid4\n",
    "from pynwb import NWBHDF5IO, NWBFile\n",
    "from pynwb.ophys import (\n",
    "    Fluorescence,\n",
    "    ImageSegmentation,\n",
    "    OnePhotonSeries,\n",
    "    OpticalChannel,\n",
    "    RoiResponseSeries\n",
    ")\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from neuralactivitycubic.input import DataLoader, ROI, GridWrapperROILoader\n",
    "from neuralactivitycubic.datamodels import Config\n",
    "from neuralactivitycubic.analysis import AnalysisROI\n",
    "from neuralactivitycubic import results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_analysis_rois(analysis_roi: AnalysisROI, config: Config) -> AnalysisROI:\n",
    "    analysis_roi.compute_mean_intensity_timeseries(config.use_frame_range, config.start_frame_idx, config.end_frame_idx)\n",
    "    if np.mean(analysis_roi.mean_intensity_over_time) >= config.mean_signal_threshold:\n",
    "        analysis_roi.detect_peaks(config.signal_to_noise_ratio, config.min_octave_span, config.noise_window_size)\n",
    "        analysis_roi.estimate_baseline(config.baseline_estimation_method)\n",
    "        analysis_roi.compute_area_under_curve()\n",
    "        analysis_roi.compute_amplitude_and_delta_f_over_f()\n",
    "        analysis_roi.compute_variance_area(config.variance_window_size)\n",
    "    return analysis_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AnalysisJob:\n",
    "\n",
    "    def __init__(self, \n",
    "                 number_of_parallel_processes: int,\n",
    "                 data_loaders: dict[str, DataLoader | list[DataLoader]],\n",
    "                 results_dir: Path | None = None\n",
    "                ) -> None:\n",
    "        self.number_of_parallel_processes = number_of_parallel_processes\n",
    "        self.recording_loader = data_loaders['recording']\n",
    "        self.results_dir = results_dir\n",
    "        self.results_dir_path: Path | None = None\n",
    "        self.nwb_metadata: dict | None = None\n",
    "        self.analysis_start_datetime: datetime | None = None\n",
    "        if 'rois' in data_loaders.keys():\n",
    "            self.rois_source = 'file'\n",
    "            self.roi_loaders = data_loaders['rois']\n",
    "        else:\n",
    "            self.rois_source = 'grid'\n",
    "            self.roi_loaders = [GridWrapperROILoader(self.recording_loader.filepath)]\n",
    "        if 'focus_area' in data_loaders.keys():\n",
    "            self.focus_area_enabled = True\n",
    "            self.focus_area_loader = data_loaders['focus_area']\n",
    "        else:\n",
    "            self.focus_area_enabled = False\n",
    "            self.focus_area = None\n",
    "\n",
    "    \n",
    "    def preview_window_size(self, window_size: int) -> tuple[Figure, Axes]:\n",
    "        self.load_data_into_memory(window_size)\n",
    "        grid_configs = self.roi_loaders[0].configs\n",
    "        fig, ax = results.plot_window_size_preview(self.recording.preview, grid_configs, self.focus_area)\n",
    "        return fig, ax\n",
    "\n",
    "    \n",
    "    def load_data_into_memory(self, window_size: int) -> None:\n",
    "        self.recording = self.recording_loader.load_and_parse_file_content()\n",
    "        if not hasattr(self, 'all_analysis_rois'):\n",
    "            self.all_analysis_rois = self._create_all_analysis_rois(window_size)\n",
    "        elif self.rois_source == 'grid':\n",
    "            if self.roi_loaders[0].window_size != window_size:\n",
    "                self.all_analysis_rois = self._create_all_analysis_rois(window_size)\n",
    "\n",
    "\n",
    "    def _create_all_analysis_rois(self, window_size: int) -> list[AnalysisROI]:     \n",
    "        self.all_rois = self._load_data_from_all_roi_loaders(window_size)\n",
    "        if self.focus_area_enabled:\n",
    "            self.focus_area = self.focus_area_loader.load_and_parse_file_content()[0]\n",
    "            self.all_rois = self._filter_rois_by_focus_area()\n",
    "        return self._create_analysis_rois()\n",
    "\n",
    "    \n",
    "    def _load_data_from_all_roi_loaders(self, window_size: int) -> list[ROI]:\n",
    "        all_rois = []\n",
    "        for roi_loader in self.roi_loaders:\n",
    "            if type(roi_loader) == GridWrapperROILoader:\n",
    "                roi_loader.set_configs_for_grid_creation(self.recording.preview.shape[1], self.recording.preview.shape[0], window_size)\n",
    "            all_rois += roi_loader.load_and_parse_file_content()\n",
    "        if self.rois_source == 'grid':\n",
    "            self.grid_configs = self.roi_loaders[0].configs\n",
    "        else:\n",
    "            self.grid_configs = None\n",
    "        return all_rois\n",
    "    \n",
    "\n",
    "    def _filter_rois_by_focus_area(self) -> list[ROI]:\n",
    "        filtered_rois = [roi for roi in self.all_rois if roi.as_polygon.within(self.focus_area.as_polygon)]\n",
    "        return filtered_rois\n",
    "        \n",
    "\n",
    "    def _create_analysis_rois(self) -> list[AnalysisROI]:\n",
    "        all_analysis_rois = []\n",
    "        if self.rois_source == 'file':\n",
    "            self._create_and_add_label_ids_to_all_rois_from_file()\n",
    "        for roi in self.all_rois:\n",
    "            roi_bounding_box_row_col_coords = get_coordinates(roi.as_polygon.envelope).astype('int')\n",
    "            row_min, col_min = roi_bounding_box_row_col_coords.min(axis=0)\n",
    "            row_max, col_max = roi_bounding_box_row_col_coords.max(axis=0)   \n",
    "            zstack = self.recording.zstack[:, row_min:row_max, col_min:col_max, :]\n",
    "            analysis_roi = AnalysisROI(roi, (row_min, col_min), zstack)\n",
    "            all_analysis_rois.append(analysis_roi)\n",
    "        return all_analysis_rois\n",
    "\n",
    "\n",
    "    def _create_and_add_label_ids_to_all_rois_from_file(self) -> None:\n",
    "        roi_count = len(self.all_rois)\n",
    "        zfill_factor = int(np.log10(roi_count)) + 1\n",
    "        for idx, roi in enumerate(self.all_rois):\n",
    "            label_id = str(idx + 1).zfill(zfill_factor)\n",
    "            roi.add_label_id(label_id)\n",
    "\n",
    "    def _create_results_dir(self) -> Path:\n",
    "        \"\"\"\n",
    "        Creates and returns the directory path where analysis results will be saved.\n",
    "\n",
    "        The directory name is constructed using the analysis start datetime, the recording filename, and optionally the focus area filename if focus area is enabled. If a custom results directory was provided during initialization, it is used instead. The method ensures the directory exists (creates it if necessary) and returns the Path object for the results directory.\n",
    "        \"\"\"\n",
    "        prefix_with_datetime = self.analysis_start_datetime.strftime('%Y_%m_%d_%H-%M-%S_results_for')\n",
    "        recording_filename = self.recording.filepath.stem\n",
    "        if self.focus_area_enabled:\n",
    "            focus_area_filename = self.focus_area.filepath.stem\n",
    "            results_dir_name = f'{prefix_with_datetime}_{recording_filename}_with_{focus_area_filename}'\n",
    "        else:\n",
    "            results_dir_name = f'{prefix_with_datetime}_{recording_filename}'\n",
    "        if self.results_dir is not None:\n",
    "            results_dir_path = self.results_dir / results_dir_name\n",
    "        else:\n",
    "            results_dir_path = self.recording.filepath.parent / results_dir_name\n",
    "        results_dir_path.mkdir(exist_ok=True, parents=True)\n",
    "        return results_dir_path\n",
    "\n",
    "    \n",
    "    def run_analysis(self, config: Config) -> None:\n",
    "        self.analysis_start_datetime = datetime.now(tzlocal())\n",
    "        self.load_data_into_memory(config.grid_size)\n",
    "        self.results_dir_path = self._create_results_dir()\n",
    "        copy_of_all_analysis_rois = self.all_analysis_rois.copy()\n",
    "        with multiprocessing.Pool(processes = self.number_of_parallel_processes) as pool:\n",
    "            processed_analysis_rois = pool.starmap(process_analysis_rois, [(analysis_roi, config) for analysis_roi in copy_of_all_analysis_rois])\n",
    "        self.all_analysis_rois = processed_analysis_rois\n",
    "\n",
    "\n",
    "    def create_results(self, config: Config, nwb_metadata: dict[str, Any] = None) -> None:\n",
    "        activity_filtered_analysis_rois = [roi for roi in self.all_analysis_rois if roi.peaks_count >= config.min_peak_count]\n",
    "        self.activity_overview_plot = results.plot_activity_overview(analysis_rois_with_sufficient_activity = activity_filtered_analysis_rois,\n",
    "                                                                     preview_image = self.recording.preview,\n",
    "                                                                     indicate_activity = True,\n",
    "                                                                     focus_area = self.focus_area,\n",
    "                                                                     grid_configs = self.grid_configs)\n",
    "        if config.save_overview_png:\n",
    "            self.activity_overview_plot[0].savefig(self.results_dir_path.joinpath('activity_overview.png'), dpi=300)\n",
    "            label_id_overview_fig, label_id_overview_ax = results.plot_rois_with_label_id_overview(\n",
    "                analysis_rois_with_sufficient_activity=activity_filtered_analysis_rois,\n",
    "                preview_image=self.recording.preview,\n",
    "                focus_area=self.focus_area,\n",
    "                grid_configs=self.grid_configs)\n",
    "            label_id_overview_fig.savefig(self.results_dir_path.joinpath('ROI_label_IDs_overview.png'), dpi=300)\n",
    "            plt.close()\n",
    "        if config.save_summary_results:\n",
    "            self._create_and_save_csv_result_files(activity_filtered_analysis_rois)\n",
    "            self._create_and_save_individual_traces_pdf_result_file(activity_filtered_analysis_rois)\n",
    "        if config.save_single_trace_results:\n",
    "            self._create_and_save_single_trace_results_as_csv(activity_filtered_analysis_rois)\n",
    "        if config.export_to_nwb:\n",
    "            self._export_all_data_to_nwb(nwb_metadata)\n",
    " \n",
    "    def _export_all_data_to_nwb(self, nwb_metadata: dict[str, Any] = None) -> None:\n",
    "        if nwb_metadata is None:\n",
    "            nwb_metadata = {}\n",
    "        nwb_file = self._initialize_nwb_file(nwb_metadata)\n",
    "        nwb_file = self._add_source_data(nwb_file, nwb_metadata)\n",
    "        nwb_file = self._add_na3_results(nwb_file)\n",
    "        self._write_nwb_file(nwb_file)\n",
    "\n",
    "\n",
    "    def _initialize_nwb_file(self, nwb_metadata: dict[str, Any]) -> NWBFile:\n",
    "        nwb_file = NWBFile(\n",
    "            session_description=\"Autogenerated NWB file by Neuralactivitycubic\",\n",
    "            identifier=str(uuid4()),\n",
    "            session_start_time=datetime.now(tzlocal()),\n",
    "            experimenter=nwb_metadata.get('experimenter', 'NA3 user'),\n",
    "            experiment_description=nwb_metadata.get('experiment_description', 'Experiment done with NA3'),\n",
    "            lab=nwb_metadata.get('lab', 'NA3 lab'),\n",
    "            institution=nwb_metadata.get('institution', 'NA3 institution'),\n",
    "            notes=nwb_metadata.get('notes', ''),\n",
    "        )\n",
    "        return nwb_file\n",
    "\n",
    "\n",
    "    def _add_source_data(self, nwb_file: NWBFile, nwb_metadata: dict[str, Any]) -> NWBFile:\n",
    "        # Add recording source data\n",
    "        microscope = nwb_file.create_device(\n",
    "            name = 'Microscope',\n",
    "            model_number=nwb_metadata.get('model_number', 'NA3 microscope'),\n",
    "            manufacturer=nwb_metadata.get('manufacturer', 'Indoc'),\n",
    "            description=nwb_metadata.get('description', ''),\n",
    "        )\n",
    "        optical_channel = OpticalChannel(\n",
    "            name = 'channel_01',\n",
    "            description = nwb_metadata.get('imaging_description', ''),\n",
    "            emission_lambda = nwb_metadata.get('emission_wavelength', 0.0),\n",
    "        )\n",
    "        imaging_plane = nwb_file.create_imaging_plane(\n",
    "            name = 'ImagingPlane',\n",
    "            optical_channel = optical_channel,\n",
    "            description = 'In vitro Calcium Imaging of neuronal cell culture',\n",
    "            device = microscope,\n",
    "            excitation_lambda = nwb_metadata.get('excitation_wavelength', 0.0),\n",
    "            indicator = nwb_metadata.get('calcium_indicator', ''),\n",
    "            location = nwb_metadata.get('location', ''),\n",
    "        )\n",
    "        cai_series = OnePhotonSeries(\n",
    "            name = 'OnePhotonSeries',\n",
    "            imaging_plane = imaging_plane,\n",
    "            unit = 'a.u.',\n",
    "            data = self.recording.zstack[:, :, :, 0], \n",
    "            rate = 10.0 #tbd\n",
    "        )\n",
    "        nwb_file.add_acquisition(cai_series)\n",
    "        # Add ROI source data:\n",
    "        ophys_module = nwb_file.create_processing_module(\n",
    "            name=\"ophys\", description=\"optical physiology processed data\"\n",
    "        )\n",
    "        img_seg = ImageSegmentation()\n",
    "        roi_plane_seg = img_seg.create_plane_segmentation(\n",
    "            name=\"PlaneSegmentation\",\n",
    "            description=\"ROIs for analysis; created manually using ImageJ2\",\n",
    "            imaging_plane=imaging_plane,\n",
    "            reference_images=cai_series,\n",
    "        )\n",
    "        ophys_module.add(img_seg)\n",
    "        roi_plane_seg.add_column(name = 'ROI_label_ID', description = 'ROI label ID assigned by neuralactivitycubic', index = False)\n",
    "        for roi in self.all_rois:\n",
    "            roi.create_nwb_compliant_pixel_mask()\n",
    "            roi_plane_seg.add_roi(pixel_mask = roi.pixel_mask, ROI_label_ID = roi.label_id)\n",
    "        return nwb_file\n",
    "\n",
    "\n",
    "    def _add_na3_results(self, nwb_file: NWBFile) -> NWBFile:\n",
    "        # Add mean intensity time series per ROI:\n",
    "        plane_segmentation = nwb_file.processing['ophys']['ImageSegmentation']['PlaneSegmentation']\n",
    "        all_rois_table_region = plane_segmentation.create_roi_table_region(description = 'All ROIs')\n",
    "        stacked_arrays = np.stack([analysis_roi.mean_intensity_over_time for analysis_roi in self.all_analysis_rois], axis=1)\n",
    "        mean_int_roi_response_series = RoiResponseSeries(\n",
    "            name=\"RoiResponseSeries\",\n",
    "            description=\"Mean intensity time series for all ROIs\",\n",
    "            data=stacked_arrays,\n",
    "            rois=all_rois_table_region,\n",
    "            unit=\"bit-values\",\n",
    "            rate=10.0, # use rate of image series in acquisition of NWB file\n",
    "        )\n",
    "        mean_int_fluorescence_series = Fluorescence(mean_int_roi_response_series)\n",
    "        nwb_file.processing['ophys'].add(mean_int_fluorescence_series)\n",
    "        # Add all analysis results\n",
    "        custom_unit_column_infos = [\n",
    "            ('ROI_label_ID', 'ROI label ID assigned by neuralactivitycubic', False),\n",
    "            ('total_peaks_count', 'Total number of detected peaks', False),\n",
    "            ('variance_area', 'Computed variance area', False),\n",
    "            ('peaks_frame_idxs', 'The frame indices of all peaks', True),\n",
    "            ('peaks_bit_value', 'The fluorescence intensities (bit values) of all peak', True),\n",
    "            ('peaks_amplitude', 'The amplitudes of all peaks (above the computed baseline)', True),\n",
    "            ('peaks_df_over_f', 'The delta-F over F values of all peaks', True),\n",
    "            ('peaks_auc', 'The area under curve values of all peaks (np.NaN for individual peaks if no AUC could be computed)', True),\n",
    "            ('peaks_classification', 'The classification of all peaks as assigned by neuralactivitycubic', True)\n",
    "        ]\n",
    "        for (name, description, index) in custom_unit_column_infos:\n",
    "            nwb_file.add_unit_column(name = name, description = description, index = index)\n",
    "        for analysis_roi in self.all_analysis_rois:\n",
    "            info = self._get_info_for_nwb_units_table_from_analysis_roi(analysis_roi)\n",
    "            nwb_file.add_unit(**info)\n",
    "        return nwb_file\n",
    "\n",
    "\n",
    "    def _write_nwb_file(self, nwb_file: NWBFile) -> None:\n",
    "        filepath = self.results_dir_path.joinpath('autogenerated_nwb_file.nwb')\n",
    "        with NWBHDF5IO(filepath, 'w') as io:\n",
    "            io.write(nwb_file)\n",
    "\n",
    "\n",
    "    def _get_info_for_nwb_units_table_from_analysis_roi(self, analysis_roi) -> dict:\n",
    "        info = {\n",
    "            'ROI_label_ID': analysis_roi.label_id, \n",
    "            'total_peaks_count': analysis_roi.peaks_count, \n",
    "            'variance_area': np.nan, \n",
    "            'peaks_frame_idxs': [], \n",
    "            'peaks_bit_value': [], \n",
    "            'peaks_amplitude': [], \n",
    "            'peaks_df_over_f': [], \n",
    "            'peaks_auc': [], \n",
    "            'peaks_classification': []\n",
    "        }\n",
    "        if hasattr(analysis_roi, 'variance_area'):\n",
    "            info['variance_area'] = analysis_roi.variance_area\n",
    "        if analysis_roi.peaks_count > 0:\n",
    "            info['peaks_frame_idxs'] = [peak.frame_idx for peak in analysis_roi.peaks.values()]\n",
    "            info['peaks_bit_value'] = [peak.intensity for peak in analysis_roi.peaks.values()]\n",
    "            if hasattr(analysis_roi, 'baseline'):\n",
    "                info['peaks_amplitude'] = [peak.amplitude for peak in analysis_roi.peaks.values()]\n",
    "                info['peaks_df_over_f'] = [peak.delta_f_over_f for peak in analysis_roi.peaks.values()]\n",
    "                info['peaks_auc'] = [peak.area_under_curve for peak in analysis_roi.peaks.values()]\n",
    "                info['peaks_classification'] = [peak.peak_type for peak in analysis_roi.peaks.values()]\n",
    "        return info\n",
    "\n",
    "\n",
    "    def _create_variance_area_dataframe(self, filtered_rois: list[AnalysisROI]) -> pd.DataFrame:\n",
    "        data = {'ROI label ID': [],\n",
    "                'Variance Area': []}\n",
    "        for roi in filtered_rois:\n",
    "            data['ROI label ID'].append(roi.label_id)\n",
    "            data['Variance Area'].append(roi.variance_area)\n",
    "        df = pd.DataFrame(data = data)\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def _create_and_save_csv_result_files(self, filtered_rois: list[AnalysisROI]) -> None:\n",
    "        if len(filtered_rois) > 0:\n",
    "            df_variance_areas = self._create_variance_area_dataframe(filtered_rois)\n",
    "            df_variance_areas.to_csv(self.results_dir_path.joinpath('Variance_area_results.csv'), index = False)\n",
    "            peak_results_per_roi = [results.export_peak_results_df_from_analysis_roi(roi) for roi in filtered_rois]\n",
    "            df_all_peak_results = pd.concat(peak_results_per_roi, ignore_index = True)\n",
    "            max_peak_count_across_all_rois = df_all_peak_results.groupby('ROI label ID').count()['peak frame index'].max()\n",
    "            zfill_factor = int(np.log10(max_peak_count_across_all_rois)) + 1\n",
    "            amplitude_and_delta_f_over_f_results_all_rois = []\n",
    "            auc_results_all_rois = []\n",
    "            for roi_label_id in df_all_peak_results['ROI label ID'].unique():\n",
    "                tmp_df_single_roi = df_all_peak_results[df_all_peak_results['ROI label ID'] == roi_label_id].copy()\n",
    "                amplitude_and_delta_f_over_f_results_all_rois.append(results.create_single_roi_amplitude_and_delta_f_over_f_results(tmp_df_single_roi, zfill_factor))\n",
    "                auc_results_all_rois.append(results.create_single_roi_auc_results(tmp_df_single_roi, zfill_factor))\n",
    "            df_all_amplitude_and_delta_f_over_f_results = pd.concat(amplitude_and_delta_f_over_f_results_all_rois, ignore_index = True)\n",
    "            df_all_auc_results = pd.concat(auc_results_all_rois, ignore_index = True)\n",
    "            # Once all DataFrames are created successfully, write them to disk \n",
    "            df_all_peak_results.to_csv(self.results_dir_path.joinpath('all_peak_results.csv'), index = False)\n",
    "            df_all_amplitude_and_delta_f_over_f_results.to_csv(self.results_dir_path.joinpath('Amplitude_and_dF_over_F_results.csv'), index = False)\n",
    "            df_all_auc_results.to_csv(self.results_dir_path.joinpath('AUC_results.csv'), index = False)\n",
    "\n",
    "    \n",
    "    def _create_and_save_individual_traces_pdf_result_file(self, filtered_rois: list[AnalysisROI]) -> None:\n",
    "            filepath = self.results_dir_path.joinpath('Individual_traces_with_identified_events.pdf')\n",
    "            with PdfPages(filepath) as pdf:\n",
    "                for indicate_activity in [True, False]:\n",
    "                    overview_fig, ax = results.plot_activity_overview(filtered_rois, self.recording.preview, indicate_activity, self.focus_area, self.grid_configs)\n",
    "                    pdf.savefig(overview_fig)\n",
    "                    plt.close()\n",
    "                label_ids_overview_fig, ax = results.plot_rois_with_label_id_overview(filtered_rois, self.recording.preview, self.focus_area, self.grid_configs)\n",
    "                pdf.savefig(label_ids_overview_fig)\n",
    "                plt.close()\n",
    "                for roi in filtered_rois:\n",
    "                    fig = results.plot_intensity_trace_with_identified_peaks_for_individual_roi(roi)\n",
    "                    pdf.savefig(fig)\n",
    "                    plt.close()\n",
    "\n",
    "\n",
    "    def _create_and_save_single_trace_results_as_csv(self, filtered_rois: list[AnalysisROI]) -> None:\n",
    "        single_trace_subdir_path = self.results_dir_path.joinpath('single_traces')\n",
    "        single_trace_subdir_path.mkdir(parents = True, exist_ok = True)\n",
    "        for analysis_roi in filtered_rois:\n",
    "            df_single_trace = self._initialize_single_trace_df(analysis_roi)\n",
    "            for peak_idx in df_single_trace[df_single_trace['is_peak'] == True].index:\n",
    "                peak = analysis_roi.peaks[peak_idx]\n",
    "                df_single_trace.at[peak_idx, 'peak_type'] = peak.peak_type\n",
    "                df_single_trace.at[peak_idx, 'amplitude'] = peak.amplitude\n",
    "                df_single_trace.at[peak_idx, 'delta_f_over_f'] = peak.delta_f_over_f\n",
    "                df_single_trace.at[peak_idx, 'has_baseline_intersections'] = peak.has_neighboring_intersections\n",
    "                if peak.has_neighboring_intersections == True:\n",
    "                    df_single_trace.at[peak_idx, 'pre_peak_intersection_idx'] = peak.frame_idxs_of_neighboring_intersections[0]\n",
    "                    df_single_trace.at[peak_idx, 'post_peak_intersection_idx'] = peak.frame_idxs_of_neighboring_intersections[1]\n",
    "                    df_single_trace.at[peak_idx, 'area_under_curve'] = peak.area_under_curve\n",
    "            self._save_single_trace_df(df_single_trace, analysis_roi, single_trace_subdir_path)\n",
    "            \n",
    "\n",
    "    def _initialize_single_trace_df(self, analysis_roi: AnalysisROI) -> pd.DataFrame:\n",
    "        is_peak_mask = np.zeros(analysis_roi.mean_intensity_over_time.shape[0], dtype=bool)\n",
    "        is_peak_mask[analysis_roi.frame_idxs_of_peaks] = True\n",
    "        data = {'intensity': analysis_roi.mean_intensity_over_time,\n",
    "                'estimated_baseline': analysis_roi.baseline,\n",
    "                'is_peak': is_peak_mask}\n",
    "        df = pd.DataFrame(data = data)\n",
    "        df.index.name = 'frame_idx'\n",
    "        new_columns = ['peak_type', \n",
    "                       'amplitude', \n",
    "                       'delta_f_over_f', \n",
    "                       'has_baseline_intersections', \n",
    "                       'pre_peak_intersection_idx', \n",
    "                       'post_peak_intersection_idx', \n",
    "                       'area_under_curve']\n",
    "        df[new_columns] = np.nan\n",
    "        df = df.astype({'peak_type': 'object',\n",
    "                        'has_baseline_intersections': 'object'})\n",
    "        return df\n",
    "\n",
    "\n",
    "    def _save_single_trace_df(self, \n",
    "                              df_single_trace: pd.DataFrame, \n",
    "                              analysis_roi: AnalysisROI,\n",
    "                              single_trace_subdir_path: Path) -> None:\n",
    "        filepath_friendly_roi_label_id = analysis_roi.label_id.replace('/', '-')\n",
    "        filepath = single_trace_subdir_path.joinpath(f'data_of_ROI_{filepath_friendly_roi_label_id}.csv')\n",
    "        df_single_trace.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "na3_nbdev",
   "language": "python",
   "name": "na3_nbdev"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
