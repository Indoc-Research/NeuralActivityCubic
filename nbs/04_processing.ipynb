{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# processing\n",
    "\n",
    "> Defines the structure of individual analysis jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.axes._axes import Axes \n",
    "from datetime import datetime\n",
    "from shapely import get_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Tuple, Dict, List, Any, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from neuralactivitycubic.input import DataLoader, ROI, GridWrapperROILoader\n",
    "from neuralactivitycubic import results\n",
    "from neuralactivitycubic.analysis import AnalysisROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_analysis_rois(analysis_roi: AnalysisROI, configs: Dict[str, Any]) -> AnalysisROI:\n",
    "    analysis_roi.compute_mean_intensity_timeseries(configs['use_frame_range'], configs['start_frame_idx'], configs['end_frame_idx'])\n",
    "    if np.mean(analysis_roi.mean_intensity_over_time) >= configs['mean_signal_threshold']:\n",
    "        analysis_roi.detect_peaks(configs['signal_to_noise_ratio'], configs['min_octave_span'], configs['noise_window_size'])\n",
    "        analysis_roi.estimate_baseline(configs['baseline_estimation_method'])\n",
    "        analysis_roi.compute_area_under_curve()\n",
    "        analysis_roi.compute_amplitude_and_delta_f_over_f()\n",
    "        analysis_roi.compute_variance_area(configs['variance_window_size'])\n",
    "    return analysis_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AnalysisJob:\n",
    "\n",
    "    def __init__(self, \n",
    "                 number_of_parallel_processes: int,\n",
    "                 data_loaders: Dict[str, Union[DataLoader, List[DataLoader]]]\n",
    "                ) -> None:\n",
    "        self.number_of_parallel_processes = number_of_parallel_processes\n",
    "        self.recording_loader = data_loaders['recording']\n",
    "        self.parent_dir_path = self.recording_loader.filepath.parent  \n",
    "        if 'rois' in data_loaders.keys():\n",
    "            self.rois_source = 'file'\n",
    "            self.roi_loaders = data_loaders['rois']\n",
    "        else:\n",
    "            self.rois_source = 'grid'\n",
    "            self.roi_loaders = [GridWrapperROILoader(self.recording_loader.filepath)]\n",
    "        if 'focus_area' in data_loaders.keys():\n",
    "            self.focus_area_enabled = True\n",
    "            self.focus_area_loader = data_loaders['focus_area']\n",
    "        else:\n",
    "            self.focus_area_enabled = False\n",
    "            self.focus_area = None\n",
    "\n",
    "    \n",
    "    def preview_window_size(self, window_size: int) -> Tuple[Figure, Axes]:\n",
    "        self.load_data_into_memory(window_size)\n",
    "        grid_configs = self.roi_loaders[0].configs\n",
    "        fig, ax = results.plot_window_size_preview(self.recording.preview, grid_configs, self.focus_area)\n",
    "        return fig, ax\n",
    "\n",
    "    \n",
    "    def load_data_into_memory(self, window_size: int) -> None:\n",
    "        if hasattr(self, 'recording') == False:\n",
    "            self.recording = self.recording_loader.load_and_parse_file_content()\n",
    "        if hasattr(self, 'all_analysis_rois') == False:\n",
    "            self.all_analysis_rois = self._create_all_analysis_rois(window_size)\n",
    "        elif self.rois_source == 'grid':\n",
    "            if self.roi_loaders[0].window_size != window_size:\n",
    "                self.all_analysis_rois = self._create_all_analysis_rois(window_size)\n",
    "\n",
    "\n",
    "    def _create_all_analysis_rois(self, window_size: int) -> List[AnalysisROI]:     \n",
    "        self.all_rois = self._load_data_from_all_roi_loaders(window_size)\n",
    "        if self.focus_area_enabled == True:\n",
    "            self.focus_area = self.focus_area_loader.load_and_parse_file_content()[0]\n",
    "            self.all_rois = self._filter_rois_by_focus_area()\n",
    "        return self._create_analysis_rois()\n",
    "\n",
    "    \n",
    "    def _load_data_from_all_roi_loaders(self, window_size: int) -> List[ROI]:\n",
    "        all_rois = []\n",
    "        for roi_loader in self.roi_loaders:\n",
    "            if type(roi_loader) == GridWrapperROILoader:\n",
    "                roi_loader.set_configs_for_grid_creation(self.recording.preview.shape[1], self.recording.preview.shape[0], window_size)\n",
    "            all_rois += roi_loader.load_and_parse_file_content()\n",
    "        if self.rois_source == 'grid':\n",
    "            self.grid_configs = self.roi_loaders[0].configs\n",
    "        else:\n",
    "            self.grid_configs = None\n",
    "        return all_rois\n",
    "    \n",
    "\n",
    "    def _filter_rois_by_focus_area(self) -> List[ROI]:\n",
    "        filtered_rois = [roi for roi in self.all_rois if roi.as_polygon.within(self.focus_area.as_polygon)]\n",
    "        return filtered_rois\n",
    "        \n",
    "\n",
    "    def _create_analysis_rois(self) -> List[AnalysisROI]:\n",
    "        all_analysis_rois = []\n",
    "        if self.rois_source == 'file':\n",
    "            self._create_and_add_label_ids_to_all_rois_from_file()\n",
    "        for roi in self.all_rois:\n",
    "            roi_bounding_box_row_col_coords = get_coordinates(roi.as_polygon.envelope).astype('int')\n",
    "            row_min, col_min = roi_bounding_box_row_col_coords.min(axis=0)\n",
    "            row_max, col_max = roi_bounding_box_row_col_coords.max(axis=0)   \n",
    "            zstack = self.recording.zstack[:, row_min:row_max, col_min:col_max, :]\n",
    "            analysis_roi = AnalysisROI(roi, (row_min, col_min), zstack)\n",
    "            all_analysis_rois.append(analysis_roi)\n",
    "        return all_analysis_rois\n",
    "\n",
    "\n",
    "    def _create_and_add_label_ids_to_all_rois_from_file(self) -> List[str]:\n",
    "        roi_count = len(self.all_rois)\n",
    "        zfill_factor = int(np.log10(roi_count)) + 1\n",
    "        for idx, roi in enumerate(self.all_rois):\n",
    "            label_id = str(idx + 1).zfill(zfill_factor)\n",
    "            roi.add_label_id(label_id)\n",
    "\n",
    "    \n",
    "    def run_analysis(self,\n",
    "                     grid_size: int,\n",
    "                     use_frame_range: bool,\n",
    "                     start_frame_idx: int,\n",
    "                     end_frame_idx: int,\n",
    "                     mean_signal_threshold: float,\n",
    "                     signal_to_noise_ratio: float,\n",
    "                     min_octave_span: float,\n",
    "                     noise_window_size: int,\n",
    "                     baseline_estimation_method: str,                     \n",
    "                     include_variance: bool,\n",
    "                     variance_window_size: int\n",
    "                    ) -> None:\n",
    "        self._set_analysis_start_datetime()\n",
    "        self.load_data_into_memory(grid_size)\n",
    "        configs = locals()\n",
    "        configs.pop('self')\n",
    "        copy_of_all_analysis_rois = self.all_analysis_rois.copy()\n",
    "        with multiprocessing.Pool(processes = self.number_of_parallel_processes) as pool:\n",
    "            processed_analysis_rois = pool.starmap(process_analysis_rois, [(analysis_roi, configs) for analysis_roi in copy_of_all_analysis_rois])\n",
    "        self.all_analysis_rois = processed_analysis_rois\n",
    "\n",
    "\n",
    "    def _set_analysis_start_datetime(self) -> None:\n",
    "            users_local_timezone = datetime.now().astimezone().tzinfo\n",
    "            self.analysis_start_datetime = datetime.now(users_local_timezone) \n",
    "\n",
    "\n",
    "    def create_results(self, \n",
    "                       save_overview_png: bool,\n",
    "                       save_summary_results: bool,\n",
    "                       save_single_trace_results: bool,\n",
    "                       min_peak_count: int,\n",
    "                       mean_signal_threshold: float,\n",
    "                       signal_to_noise_ratio: float\n",
    "                      ) -> None:\n",
    "        self._ensure_results_dir_exists()\n",
    "        activity_filtered_analysis_rois = [roi for roi in self.all_analysis_rois if roi.peaks_count >= min_peak_count]\n",
    "        self.activity_overview_plot = results.plot_activity_overview(analysis_rois_with_sufficient_activity = activity_filtered_analysis_rois,\n",
    "                                                                     preview_image = self.recording.preview,\n",
    "                                                                     indicate_activity = True,\n",
    "                                                                     focus_area = self.focus_area,\n",
    "                                                                     grid_configs = self.grid_configs)\n",
    "        if save_overview_png == True:\n",
    "            self.activity_overview_plot[0].savefig(self.results_dir_path.joinpath('activity_overview.png'), dpi = 300)\n",
    "            label_id_overview_fig, label_id_overview_ax = results.plot_rois_with_label_id_overview(analysis_rois_with_sufficient_activity = activity_filtered_analysis_rois,\n",
    "                                                                                                   preview_image = self.recording.preview,\n",
    "                                                                                                   focus_area = self.focus_area,\n",
    "                                                                                                   grid_configs = self.grid_configs)\n",
    "            label_id_overview_fig.savefig(self.results_dir_path.joinpath('ROI_label_IDs_overview.png'), dpi = 300)\n",
    "            plt.close()\n",
    "        if save_summary_results == True:\n",
    "            self._create_and_save_csv_result_files(activity_filtered_analysis_rois)\n",
    "            self._create_and_save_individual_traces_pdf_result_file(activity_filtered_analysis_rois)\n",
    "        if save_single_trace_results == True:\n",
    "            self._create_and_save_single_trace_results_as_csv(activity_filtered_analysis_rois)\n",
    "\n",
    "\n",
    "    def _ensure_results_dir_exists(self, subdir_name_to_check: str | None = None) -> None:\n",
    "        if hasattr(self, 'results_dir_path') == False:\n",
    "            prefix_with_datetime = self.analysis_start_datetime.strftime('%Y_%m_%d_%H-%M-%S_results_for')\n",
    "            recording_filename_without_extension = self.recording.filepath.name.replace(self.recording.filepath.suffix, '')\n",
    "            if self.focus_area_enabled == True:\n",
    "                focus_area_filename_without_extension = self.focus_area.filepath.name.replace(self.focus_area.filepath.suffix, '')\n",
    "                results_dir_name = f'{prefix_with_datetime}_{recording_filename_without_extension}_with_{focus_area_filename_without_extension}'                \n",
    "            else:\n",
    "                results_dir_name = f'{prefix_with_datetime}_{recording_filename_without_extension}'\n",
    "            self.results_dir_path = self.parent_dir_path.joinpath(results_dir_name)\n",
    "            self.results_dir_path.mkdir()\n",
    "        if type(subdir_name_to_check) == str:\n",
    "            subdir_path = self.results_dir_path.joinpath(subdir_name_to_check)\n",
    "            if subdir_path.is_dir() == False:\n",
    "                subdir_path.mkdir()\n",
    "\n",
    "\n",
    "    def _create_variance_area_dataframe(self, filtered_rois: List[AnalysisROI]) -> pd.DataFrame:\n",
    "        data = {'ROI label ID': [],\n",
    "                'Variance Area': []}\n",
    "        for roi in filtered_rois:\n",
    "            data['ROI label ID'].append(roi.label_id)\n",
    "            data['Variance Area'].append(roi.variance_area)\n",
    "        df = pd.DataFrame(data = data)\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def _create_and_save_csv_result_files(self, filtered_rois: List[AnalysisROI]) -> None:\n",
    "        if len(filtered_rois) > 0:\n",
    "            df_variance_areas = self._create_variance_area_dataframe(filtered_rois)\n",
    "            df_variance_areas.to_csv(self.results_dir_path.joinpath('Variance_area_results.csv'), index = False)\n",
    "            peak_results_per_roi = [results.export_peak_results_df_from_analysis_roi(roi) for roi in filtered_rois]\n",
    "            df_all_peak_results = pd.concat(peak_results_per_roi, ignore_index = True)\n",
    "            max_peak_count_across_all_rois = df_all_peak_results.groupby('ROI label ID').count()['peak frame index'].max()\n",
    "            zfill_factor = int(np.log10(max_peak_count_across_all_rois)) + 1\n",
    "            amplitude_and_delta_f_over_f_results_all_rois = []\n",
    "            auc_results_all_rois = []\n",
    "            for roi_label_id in df_all_peak_results['ROI label ID'].unique():\n",
    "                tmp_df_single_roi = df_all_peak_results[df_all_peak_results['ROI label ID'] == roi_label_id].copy()\n",
    "                amplitude_and_delta_f_over_f_results_all_rois.append(results.create_single_roi_amplitude_and_delta_f_over_f_results(tmp_df_single_roi, zfill_factor))\n",
    "                auc_results_all_rois.append(results.create_single_roi_auc_results(tmp_df_single_roi, zfill_factor))\n",
    "            df_all_amplitude_and_delta_f_over_f_results = pd.concat(amplitude_and_delta_f_over_f_results_all_rois, ignore_index = True)\n",
    "            df_all_auc_results = pd.concat(auc_results_all_rois, ignore_index = True)\n",
    "            # Once all DataFrames are created successfully, write them to disk \n",
    "            df_all_peak_results.to_csv(self.results_dir_path.joinpath('all_peak_results.csv'), index = False)\n",
    "            df_all_amplitude_and_delta_f_over_f_results.to_csv(self.results_dir_path.joinpath('Amplitude_and_dF_over_F_results.csv'), index = False)\n",
    "            df_all_auc_results.to_csv(self.results_dir_path.joinpath('AUC_results.csv'), index = False)\n",
    "\n",
    "    \n",
    "    def _create_and_save_individual_traces_pdf_result_file(self, filtered_rois: List[AnalysisROI]) -> None:\n",
    "            filepath = self.results_dir_path.joinpath('Individual_traces_with_identified_events.pdf')\n",
    "            with PdfPages(filepath) as pdf:\n",
    "                for indicate_activity in [True, False]:\n",
    "                    overview_fig, ax = results.plot_activity_overview(filtered_rois, self.recording.preview, indicate_activity, self.focus_area, self.grid_configs)\n",
    "                    pdf.savefig(overview_fig)\n",
    "                    plt.close()\n",
    "                label_ids_overview_fig, ax = results.plot_rois_with_label_id_overview(filtered_rois, self.recording.preview, self.focus_area, self.grid_configs)\n",
    "                pdf.savefig(label_ids_overview_fig)\n",
    "                plt.close()\n",
    "                for roi in filtered_rois:\n",
    "                    fig = results.plot_intensity_trace_with_identified_peaks_for_individual_roi(roi)\n",
    "                    pdf.savefig(fig)\n",
    "                    plt.close()\n",
    "\n",
    "\n",
    "    def _create_and_save_single_trace_results_as_csv(self, filtered_rois: List[AnalysisROI]) -> None:\n",
    "        self._ensure_results_dir_exists(subdir_name_to_check='single_traces')\n",
    "        single_trace_subdir_path = self.results_dir_path.joinpath('single_traces')\n",
    "        for analysis_roi in filtered_rois:\n",
    "            df_single_trace = self._initialize_single_trace_df(analysis_roi)\n",
    "            for peak_idx in df_single_trace[df_single_trace['is_peak'] == True].index:\n",
    "                peak = analysis_roi.peaks[peak_idx]\n",
    "                df_single_trace.at[peak_idx, 'peak_type'] = peak.peak_type\n",
    "                df_single_trace.at[peak_idx, 'amplitude'] = peak.amplitude\n",
    "                df_single_trace.at[peak_idx, 'delta_f_over_f'] = peak.delta_f_over_f\n",
    "                df_single_trace.at[peak_idx, 'has_baseline_intersections'] = peak.has_neighboring_intersections\n",
    "                if peak.has_neighboring_intersections == True:\n",
    "                    df_single_trace.at[peak_idx, 'pre_peak_intersection_idx'] = peak.frame_idxs_of_neighboring_intersections[0]\n",
    "                    df_single_trace.at[peak_idx, 'post_peak_intersection_idx'] = peak.frame_idxs_of_neighboring_intersections[1]\n",
    "                    df_single_trace.at[peak_idx, 'area_under_curve'] = peak.area_under_curve\n",
    "            self._save_single_trace_df(df_single_trace, analysis_roi, single_trace_subdir_path)\n",
    "            \n",
    "\n",
    "    def _initialize_single_trace_df(self, analysis_roi: AnalysisROI) -> pd.DataFrame:\n",
    "        is_peak_mask = np.zeros(analysis_roi.mean_intensity_over_time.shape[0], dtype=bool)\n",
    "        is_peak_mask[analysis_roi.frame_idxs_of_peaks] = True\n",
    "        data = {'intensity': analysis_roi.mean_intensity_over_time,\n",
    "                'estimated_baseline': analysis_roi.baseline,\n",
    "                'is_peak': is_peak_mask}\n",
    "        df = pd.DataFrame(data = data)\n",
    "        df.index.name = 'frame_idx'\n",
    "        new_columns = ['peak_type', \n",
    "                       'amplitude', \n",
    "                       'delta_f_over_f', \n",
    "                       'has_baseline_intersections', \n",
    "                       'pre_peak_intersection_idx', \n",
    "                       'post_peak_intersection_idx', \n",
    "                       'area_under_curve']\n",
    "        df[new_columns] = np.nan\n",
    "        df = df.astype({'peak_type': 'object',\n",
    "                        'has_baseline_intersections': 'object'})\n",
    "        return df\n",
    "\n",
    "\n",
    "    def _save_single_trace_df(self, \n",
    "                              df_single_trace: pd.DataFrame, \n",
    "                              analysis_roi: AnalysisROI,\n",
    "                              single_trace_subdir_path: Path) -> None:\n",
    "        filepath_friendly_roi_label_id = analysis_roi.label_id.replace('/', '-')\n",
    "        filepath = single_trace_subdir_path.joinpath(f'data_of_ROI_{filepath_friendly_roi_label_id}.csv')\n",
    "        df_single_trace.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "na3_nbdev",
   "language": "python",
   "name": "na3_nbdev"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
