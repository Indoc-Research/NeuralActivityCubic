{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datamodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b14e0c7b9418495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6295a3ec1a42e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "\n",
    "from typing import Any\n",
    "from dataclasses import dataclass, asdict, fields\n",
    "from pathlib import Path\n",
    "from fastcore.test import test_fail\n",
    "\n",
    "@dataclass\n",
    "class BaseDataClass:\n",
    "    def to_dict(self) -> dict[str, Any]:\n",
    "        \"\"\"Returning contents of the dataclass as a dictionary.\"\"\"\n",
    "        return asdict(self)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, **params) -> \"BaseDataClass\":\n",
    "        \"\"\"Creating dataclass from dictionary with data validation.\"\"\"\n",
    "        # getting all class fields\n",
    "        all_fields = {field.name: field.type for field in fields(cls)}\n",
    "        cleaned_params = {}\n",
    "        for param in params.items():\n",
    "            key, value = param\n",
    "            # checking if input param is in fields\n",
    "            if key in all_fields:\n",
    "                # checking if value type is correct\n",
    "                # bool is a subclass of int\n",
    "                # print(value, type(value), all_fields[key])\n",
    "                if type(value) is bool:\n",
    "                    if type(value) is all_fields[key]:\n",
    "                        cleaned_params[key] = value\n",
    "                else:\n",
    "                    if isinstance(value, all_fields[key]):\n",
    "                        cleaned_params[key] = value\n",
    "        return cls(**cleaned_params)\n",
    "\n",
    "    @classmethod\n",
    "    def validate(cls, params) -> dict[str, Any]:\n",
    "        instance = cls.from_dict(**params)\n",
    "        return instance.to_dict()\n",
    "\n",
    "@dataclass\n",
    "class Config(BaseDataClass):\n",
    "    window_size: int = 10\n",
    "    signal_to_noise_ratio: float = 3.0\n",
    "    noise_window_size: int = 200\n",
    "    signal_average_threshold: float = 10.0\n",
    "    minimum_activity_counts: int = 2\n",
    "    baseline_estimation_method: str = 'asls'\n",
    "    include_variance: bool = False\n",
    "    variance: int = 15\n",
    "    limit_analysis_to_frame_interval: bool = False\n",
    "    start_frame_idx: int = 0\n",
    "    end_frame_idx: int = 500\n",
    "    configure_octaves: bool = False\n",
    "    octaves_ridge_needs_to_spann: float = 1.0\n",
    "    save_overview_png: bool = True\n",
    "    save_detailed_results: bool = True\n",
    "    batch_mode: bool = False\n",
    "    focus_area_enabled: bool = False\n",
    "    roi_mode: str = 'grid'\n",
    "    save_single_trace_results: bool = False\n",
    "    data_source_path: Path = None\n",
    "    recording_filepath: Path = None\n",
    "    focus_area_filepath: Path = None\n",
    "    filepath_analyzed_rois: list[str] = None\n",
    "\n",
    "@dataclass\n",
    "class AnalysisConfig(BaseDataClass):\n",
    "    window_size: int\n",
    "    limit_analysis_to_frame_interval: bool\n",
    "    start_frame_idx: int\n",
    "    end_frame_idx: int\n",
    "    signal_average_threshold: float\n",
    "    signal_to_noise_ratio: float\n",
    "    octaves_ridge_needs_to_spann: float\n",
    "    noise_window_size: int\n",
    "    baseline_estimation_method: str\n",
    "    include_variance: bool\n",
    "    variance: int\n",
    "\n",
    "@dataclass\n",
    "class ResultsConfig(BaseDataClass):\n",
    "    save_overview_png: bool\n",
    "    save_detailed_results: bool\n",
    "    save_single_trace_results: bool\n",
    "    minimum_activity_counts: int\n",
    "    signal_average_threshold: float\n",
    "    signal_to_noise_ratio: float\n",
    "\n",
    "@dataclass\n",
    "class AnalysisJobConfig(BaseDataClass):\n",
    "    roi_mode: str\n",
    "    batch_mode: bool\n",
    "    focus_area_enabled: bool\n",
    "    data_source_path: Path\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Peak(BaseDataClass):\n",
    "    frame_idx: int\n",
    "    intensity: float\n",
    "    amplitude: float | None = None\n",
    "    delta_f_over_f: float | None = None\n",
    "    has_neighboring_intersections: bool | None = None\n",
    "    frame_idxs_of_neighboring_intersections: tuple | None = None\n",
    "    area_under_curve: float | None = None\n",
    "    peak_type: str | None = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7251f15fbfcaa240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "# from neuralactivitycubic.view import WidgetsInterface\n",
    "\n",
    "correct_general_config = Config().to_dict()  # needs to be added here until implemented in GUI\n",
    "\n",
    "recording_filepath = Path('../test_data/00/spiking_neuron.avi')\n",
    "correct_analysis_job_config = {\n",
    "    'roi_mode': 'grid',\n",
    "    'batch_mode': True,\n",
    "    'focus_area_enabled': True,\n",
    "    'data_source_path': recording_filepath,\n",
    "}\n",
    "correct_peak_config = {\n",
    "    'frame_idx': 10,\n",
    "    'intensity': 10.0,\n",
    "    'amplitude': 10.0,\n",
    "    'delta_f_over_f': 10.0,\n",
    "    'has_neighboring_intersections': True,\n",
    "    'frame_idxs_of_neighboring_intersections': (1,2),\n",
    "    'area_under_curve': 10.0,\n",
    "    'peak_type': 'normal',\n",
    "}\n",
    "minimal_peak_config = {\n",
    "    'frame_idx': 10,\n",
    "    'intensity': 10.0,\n",
    "}\n",
    "\n",
    "def test_correct_analysis_config():\n",
    "    return AnalysisConfig.from_dict(**correct_general_config)\n",
    "\n",
    "def test_correct_analysis_job_config():\n",
    "    return AnalysisJobConfig.from_dict(**correct_analysis_job_config)\n",
    "\n",
    "def test_correct_results_config():\n",
    "    return ResultsConfig.from_dict(**correct_general_config)\n",
    "\n",
    "def test_correct_peak_config():\n",
    "    return Peak.from_dict(**correct_peak_config)\n",
    "\n",
    "def test_minimal_peak_config():\n",
    "    return Peak.from_dict(**minimal_peak_config)\n",
    "\n",
    "incomplete_analysis_config = correct_general_config.copy()\n",
    "incomplete_analysis_config.pop('window_size')\n",
    "\n",
    "def test_incomplete_analysis_config():\n",
    "    return AnalysisConfig.from_dict(**incomplete_analysis_config)\n",
    "\n",
    "wrong_analysis_config = correct_general_config.copy()\n",
    "wrong_analysis_config['window_size'] = 'haha'\n",
    "\n",
    "def test_wrong_analysis_config():\n",
    "    return AnalysisConfig.from_dict(**wrong_analysis_config)\n",
    "\n",
    "incomplete_results_config = correct_general_config.copy()\n",
    "incomplete_results_config.pop('signal_to_noise_ratio')\n",
    "\n",
    "def test_incomplete_results_config():\n",
    "    return ResultsConfig.from_dict(**incomplete_results_config)\n",
    "\n",
    "wrong_results_config = correct_general_config.copy()\n",
    "wrong_results_config['signal_to_noise_ratio'] = True\n",
    "\n",
    "def test_wrong_results_config():\n",
    "    return ResultsConfig.from_dict(**wrong_results_config)\n",
    "\n",
    "incomplete_peak_config = correct_peak_config.copy()\n",
    "incomplete_peak_config.pop('frame_idx')\n",
    "\n",
    "def test_incomplete_peak_config():\n",
    "    return Peak.from_dict(**incomplete_peak_config)\n",
    "\n",
    "wrong_peak_config = correct_peak_config.copy()\n",
    "wrong_peak_config['frame_idx'] = False\n",
    "\n",
    "def test_wrong_peak_config():\n",
    "    return Peak.from_dict(**wrong_peak_config)\n",
    "\n",
    "# Add a check to ensure Config contains all required fields for other dataclasses\n",
    "def _check_config_fields():\n",
    "    config_fields = set(Config.__dataclass_fields__.keys())\n",
    "    required = {\n",
    "        'AnalysisConfig': set(AnalysisConfig.__dataclass_fields__.keys()),\n",
    "        'ResultsConfig': set(ResultsConfig.__dataclass_fields__.keys()),\n",
    "        'AnalysisJobConfig': set(AnalysisJobConfig.__dataclass_fields__.keys()),\n",
    "        # Peak is not a config, so skip\n",
    "    }\n",
    "    for name, fields_set in required.items():\n",
    "        missing = fields_set - config_fields\n",
    "        if missing:\n",
    "            print(f\"Config is missing fields required by {name}: {missing}\")\n",
    "        else:\n",
    "            print(f\"Config contains all fields required by {name}.\")\n",
    "\n",
    "_check_config_fields()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2074613d837e3967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# correct inputs tests\n",
    "assert isinstance(test_correct_analysis_config(), AnalysisConfig)\n",
    "assert isinstance(test_correct_analysis_job_config(), AnalysisJobConfig)\n",
    "assert isinstance(test_correct_results_config(), ResultsConfig)\n",
    "assert isinstance(test_correct_peak_config(), Peak)\n",
    "assert isinstance(test_minimal_peak_config(), Peak)\n",
    "\n",
    "# incomplete inputs tests\n",
    "test_fail(test_incomplete_analysis_config)\n",
    "test_fail(test_incomplete_results_config)\n",
    "test_fail(test_incomplete_peak_config)\n",
    "\n",
    "# wrong inputs tests\n",
    "test_fail(test_wrong_analysis_config)\n",
    "test_fail(test_wrong_results_config)\n",
    "test_fail(test_wrong_peak_config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
