{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datamodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b14e0c7b9418495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6295a3ec1a42e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from typing import Any, get_args\n",
    "from types import UnionType, GenericAlias\n",
    "from dataclasses import dataclass, asdict, fields\n",
    "from pathlib import Path\n",
    "from enum import Enum, EnumType\n",
    "from itertools import chain\n",
    "\n",
    "from json import dumps\n",
    "\n",
    "class BaselineEstimationMethod(str, Enum):\n",
    "    \"\"\"\n",
    "    Enum for baseline estimation methods used in analysis.\n",
    "    \"\"\"\n",
    "    ASLS = 'asls'\n",
    "    FABC = 'fabc'\n",
    "    PASLS = 'pasls'\n",
    "    SDD = 'sdd'\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value\n",
    "\n",
    "class ROIMode(str, Enum):\n",
    "    \"\"\"\n",
    "    Enum for ROI modes used in analysis.\n",
    "    \"\"\"\n",
    "    GRID = 'grid'\n",
    "    FILE = 'file'\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value\n",
    "\n",
    "@dataclass\n",
    "class BaseDataClass:\n",
    "    def to_dict(self) -> dict[str, Any]:\n",
    "        \"\"\"Returning contents of the dataclass as a dictionary.\"\"\"\n",
    "        return asdict(self)\n",
    "\n",
    "\n",
    "    def display_all_attributes(self) -> list[str]:\n",
    "        return [f'{key}: {value}' for key, value in self.to_dict().items()]\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, **params) -> \"BaseDataClass\":\n",
    "        \"\"\"Creating dataclass from dictionary with data validation.\"\"\"\n",
    "\n",
    "        def _unpack_unions(_type: UnionType | type) -> list[type]:\n",
    "            \"\"\"\n",
    "            Unpack UnionType to get all types in the union.\n",
    "            \"\"\"\n",
    "            if type(_type) is not UnionType:\n",
    "                return [_type]\n",
    "            else:\n",
    "                return list(chain.from_iterable([_unpack_unions(t) for t in get_args(_type)]))\n",
    "\n",
    "        def _unpack_parameterized_generic(_type: GenericAlias | type) -> type:\n",
    "            \"\"\"\n",
    "            Unpack parameterized generic types to get the base type.\n",
    "            \"\"\"\n",
    "            if hasattr(_type, '__origin__'):\n",
    "                # if type is a parameterized generic, return its origin\n",
    "                # checking if __args__ are correct is left as an exercise for the reader\n",
    "                return _type.__origin__\n",
    "            else:\n",
    "                # otherwise, return the type itself\n",
    "                return _type\n",
    "\n",
    "        # getting all class fields\n",
    "        all_fields = {field.name: field.type for field in fields(cls)}\n",
    "        for key, value in params.items():\n",
    "            # checking if input param is in fields\n",
    "            if key in all_fields:\n",
    "                if value is not None:\n",
    "                    if type(all_fields[key]) is UnionType:\n",
    "                        # if field is UnionType, check if value is in any of the types\n",
    "                        if not any(isinstance(value, _unpack_parameterized_generic(t)) for t in _unpack_unions(all_fields[key])):\n",
    "                            raise TypeError(f'Wrong type for the field {key}')\n",
    "                    # checking if value type is correct\n",
    "                    # bool is a subclass of int\n",
    "                    elif type(value) is bool:\n",
    "                        if not type(value) is all_fields[key]:\n",
    "                            raise TypeError(f'Wrong type for the field {key}')\n",
    "                    # instead of checking for EnumType, we check if the value is in the Enum\n",
    "                    elif type(all_fields[key]) is EnumType:\n",
    "                        if value not in list(all_fields[key]):\n",
    "                            raise ValueError(f'Wrong value for the field {key}')\n",
    "                    else:\n",
    "                        if not isinstance(value, _unpack_parameterized_generic(all_fields[key])):\n",
    "                            raise TypeError(f'Wrong type for the field {key}')\n",
    "        return cls(**params)\n",
    "\n",
    "    @classmethod\n",
    "    def validate(cls, params) -> dict[str, Any]:\n",
    "        instance = cls.from_dict(**params)\n",
    "        return instance.to_dict()\n",
    "\n",
    "@dataclass\n",
    "class Config(BaseDataClass):\n",
    "    \"\"\"\n",
    "    Configuration for analysis.\n",
    "\n",
    "    Attributes:\n",
    "        ### General Settings ###\n",
    "\n",
    "        data_source_path (str, default=None):\n",
    "            Path to the source data file or directory to be analyzed. Must comply with the source data structure\n",
    "            that is defined for the corresponding usage modes (see here:\n",
    "            https://indoc-research.github.io/NeuralActivityCubic/using_the_gui.html#source-data-structure).\n",
    "            Alternatively, source data locations can be defined using `recording_filepath`, `roi_filepath`,\n",
    "            and `focus_area_filepath`.\n",
    "\n",
    "        recording_filepath (str, default=None):\n",
    "            Path to the recording file to be analyzed. Can be used instead of `data_source_path` to\n",
    "            define the source data location.\n",
    "\n",
    "        roi_filepath (str | list[str], default=None):\n",
    "            Path or list of Paths to files that define the ROIs that are to be analyzed when `roi_mode = file`.\n",
    "            Can be used instead of `data_source_path` to define source data locations.\n",
    "\n",
    "        focus_area_filepath (str | list[str], default=None):\n",
    "            Path or list of Paths to files that define the focus areas to which analysis shall be restricted\n",
    "            when `focus_area_enabled = True`. Can be used instead of `data_source_path` to define source data\n",
    "            locations.\n",
    "\n",
    "        roi_mode (str, default='grid'):\n",
    "            Mode for defining regions of interest (ROIs) that are analyzed for activity. Options are `grid` for\n",
    "            automatic grid-based ROIs creation and `file` to load predefined ROIs from supplied files.\n",
    "\n",
    "        batch_mode (bool, default=False):\n",
    "            Whether to enable batch mode for processing multiple recordings sequentially. Requires\n",
    "            `data_source_path` to be used and is not compatible with definition of individual source data\n",
    "            locations.\n",
    "\n",
    "        focus_area_enabled (bool, default=False):\n",
    "            Whether to restrict analysis only to ROIs within specific focus area(s).\n",
    "\n",
    "\n",
    "        ### Analysis Settings ###\n",
    "\n",
    "        grid_size (int, default=10):\n",
    "            Size (in pixels) of the individual squares forming the ROI grid when `roi_mode = grid`. For example,\n",
    "            a value of 10 generates a grid composed of 10 × 10 pixel ROIs.\n",
    "\n",
    "        signal_to_noise_ratio (float, default=3.0):\n",
    "            Minimum signal-to-noise ratio (SNR) used by SciPy's `find_peaks_cwt` function (see here:\n",
    "            https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.find_peaks_cwt.html) as `min_snr`\n",
    "            for identifying peaks in the ROI signal intensity traces.\n",
    "\n",
    "        noise_window_size (int, default=200):\n",
    "            Window size (in frames) used by SciPy's `find_peaks_cwt` function (see here:\n",
    "            https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.find_peaks_cwt.html) as `window_size`\n",
    "            for estimating the local noise level when identifying signal peaks.\n",
    "\n",
    "        mean_signal_threshold (float, default=10.0): # previously: signal_average_threshold\n",
    "            Minimum average intensity across the entire analysis interval required for a ROI to be considered for\n",
    "            peak detection. Helps exclude regions with low baseline signal by filtering out background noise before\n",
    "            analysis.\n",
    "\n",
    "        min_peak_count (int, default=2):\n",
    "            Minimum number of detected peaks required in a ROI for it to be included in the final analysis results.\n",
    "            ROIs with fewer peaks than this threshold are excluded. Set to `0` if all ROIs shall be included.\n",
    "\n",
    "        baseline_estimation_method (str, default='asls'):\n",
    "            Method used to estimate the signal baseline, required for calculating area-under-curve (AUC) of detected\n",
    "            peaks. Options are based on the pybaselines library (see here:\n",
    "            https://pybaselines.readthedocs.io/en/latest/) and are:\n",
    "                - `asls`: Asymmetric Least Squares.\n",
    "                - `fabc`: Fully Automatic Baseline Correction.\n",
    "                - `pasls`: Peaked Signal's Asymmetric Least Squares.\n",
    "                - `sdd`: Standard Deviation Distribution.\n",
    "            Each method is applied with its default parameters as defined in pybaselines.\n",
    "\n",
    "        include_variance (bool, default=False):\n",
    "            Whether to compute signal variance as a proxy for neuronal excitability. Enables sliding window\n",
    "            variance analysis for each ROI.\n",
    "\n",
    "        variance_window_size (int, default=15):\n",
    "            Size of the sliding window (in frames) used to compute signal variance for each ROI when\n",
    "            `include_variance = True`.\n",
    "\n",
    "        use_frame_range (bool, default=False):\n",
    "            Whether to analyze only a specific frame interval from the recording. When enabled, analysis is limited\n",
    "            to frames between `frame_start` and `frame_end`, inclusive.\n",
    "\n",
    "        start_frame_idx (int, default=0):\n",
    "            Index of the first frame to include in the analysis interval (inclusive) if `use_frame_range = True`.\n",
    "\n",
    "        end_frame_idx (int, default=500):\n",
    "            Index of the last frame to include in the analysis interval (inclusive) if `use_frame_range = True`.\n",
    "\n",
    "        customize_octave_filtering (bool, default=False):\n",
    "            Enables manual configuration of octave-based peak filtering via `min_octave_span`. This option should\n",
    "            only be used by advanced users familiar with na3`s internal logic.\n",
    "\n",
    "        min_octave_span  (float, default=1.0):\n",
    "            Minimum number of octaves a peak ridge must span to be considered if `customize_octave_filtering = True`.\n",
    "            Used to compute `min_length` for SciPy´s `find_peaks_cwt` function, based on the number of frames.\n",
    "\n",
    "\n",
    "        ### Results Settings ###\n",
    "\n",
    "        results_filepath (str, default=None):\n",
    "            Path to the directory where analysis results will be saved. If not specified, results are saved in the\n",
    "            current working directory.\n",
    "\n",
    "        export_to_nwb (bool, default=True):\n",
    "            Whether to generate an additional NWB (NeurodataWithoutBorders - https://nwb.org/) file alongside\n",
    "            the standard result outputs. NWB is an open standard for organizing and sharing\n",
    "            neurophysiology data, supporting long-term accessibility, reproducibility, and\n",
    "            integration with other neuroscience tools. Enabling this option enhances data\n",
    "            portability and compliance with community best practices.\n",
    "\n",
    "        save_overview_png (bool, default=True):\n",
    "            Whether to save an overview PNG image summarizing the analysis results.\n",
    "\n",
    "        save_summary_results (bool, default=True):\n",
    "            Whether to save detailed results, including the following files, depending on your analysis settings:\n",
    "                - Individual_traces_with_identified_events.pdf\n",
    "                - all_peak_results.csv\n",
    "                - Amplitude_and_dF_over_F_results.csv\n",
    "                - AUC_results.csv\n",
    "                - Variance_area_results.csv\n",
    "\n",
    "        save_single_trace_results (bool, default=False):\n",
    "            Whether to save individual trace results for each ROI separately.\n",
    "    \"\"\"\n",
    "    batch_mode: bool = False\n",
    "    baseline_estimation_method: BaselineEstimationMethod = BaselineEstimationMethod.ASLS\n",
    "    customize_octave_filtering: bool = False\n",
    "    data_source_path: str = None\n",
    "    end_frame_idx: int = 500\n",
    "    export_to_nwb: bool = True\n",
    "    focus_area_enabled: bool = False\n",
    "    focus_area_filepath: str | list[str] = None\n",
    "    grid_size: int = 10\n",
    "    include_variance: bool = False\n",
    "    mean_signal_threshold: float = 10.0\n",
    "    min_octave_span: float = 1.0\n",
    "    min_peak_count: int = 2\n",
    "    noise_window_size: int = 200\n",
    "    recording_filepath: str = None\n",
    "    results_filepath: str = None\n",
    "    roi_filepath: str | list[str] = None\n",
    "    roi_mode: ROIMode = ROIMode.GRID\n",
    "    save_overview_png: bool = True\n",
    "    save_single_trace_results: bool = False\n",
    "    save_summary_results: bool = True\n",
    "    signal_to_noise_ratio: float = 3.0\n",
    "    start_frame_idx: int = 0\n",
    "    use_frame_range: bool = False\n",
    "    variance_window_size: int = 15\n",
    "\n",
    "    # lazy collection of all filepaths\n",
    "    _paths = ['data_source_path', 'recording_filepath', 'roi_filepath', 'focus_area_filepath', 'results_filepath']\n",
    "\n",
    "\n",
    "    def __post_init__(self):\n",
    "\n",
    "        def _transform_filepath_or_list(fp: str | list[str] | None) -> Path | list[Path] | None:\n",
    "            \"\"\"\n",
    "            Transform a string or list of strings to a Path or list of Paths.\n",
    "            \"\"\"\n",
    "            if isinstance(fp, str):\n",
    "                return Path(fp)\n",
    "            elif isinstance(fp, list):\n",
    "                return [Path(p) for p in fp]\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        if self.data_source_path is not None:\n",
    "            if self.roi_filepath is not None or self.recording_filepath is not None:\n",
    "                raise ValueError('Cannot specify both `data_source_path` and `roi_filepath` or `recording_filepath`')\n",
    "        for attr in self._paths:\n",
    "            setattr(self, attr, _transform_filepath_or_list(getattr(self, attr)))\n",
    "\n",
    "    def to_json(self) -> str:\n",
    "        \"\"\"Returning contents of the dataclass as a JSON string.\"\"\"\n",
    "        config_dict = self.to_dict()\n",
    "        config_dict[\"data_source_path\"] = str(config_dict[\"data_source_path\"]) if config_dict[\"data_source_path\"] else None\n",
    "        config_dict[\"recording_filepath\"] = str(config_dict[\"recording_filepath\"]) if config_dict[\"recording_filepath\"] else None\n",
    "        config_dict[\"results_filepath\"] = str(config_dict[\"results_filepath\"]) if config_dict[\"results_filepath\"] else None\n",
    "        config_dict[\"focus_area_filepath\"] = str(config_dict[\"focus_area_filepath\"]) if config_dict[\"focus_area_filepath\"] else None\n",
    "        if type(config_dict[\"roi_filepath\"]) is list:\n",
    "            config_dict[\"roi_filepath\"] = [str(roi) for roi in config_dict[\"roi_filepath\"]]\n",
    "        elif type(config_dict[\"roi_filepath\"]) is str:\n",
    "            config_dict[\"roi_filepath\"] = str(config_dict[\"roi_filepath\"])\n",
    "        else:\n",
    "            config_dict[\"roi_filepath\"] = None\n",
    "        return dumps(config_dict)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Peak(BaseDataClass):\n",
    "    frame_idx: int\n",
    "    intensity: float\n",
    "    amplitude: float | None = None\n",
    "    delta_f_over_f: float | None = None\n",
    "    has_neighboring_intersections: bool | None = None\n",
    "    frame_idxs_of_neighboring_intersections: tuple | None = None\n",
    "    area_under_curve: float | None = None\n",
    "    peak_type: str | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f148b66-abfd-4774-8936-2c2bda5a7f9f",
   "metadata": {},
   "source": [
    "## Tests:\n",
    "\n",
    "Setup for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7251f15fbfcaa240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_fail\n",
    "\n",
    "filepath = '../test_data/00/spiking_neuron.avi'\n",
    "\n",
    "correct_general_config = Config().to_dict()\n",
    "correct_general_config['data_source_path'] = filepath\n",
    "\n",
    "example_general_config = dict(\n",
    "    batch_mode=False,\n",
    "    baseline_estimation_method=BaselineEstimationMethod.ASLS,\n",
    "    customize_octave_filtering=False,\n",
    "    data_source_path=filepath,\n",
    "    end_frame_idx=500,\n",
    "    export_to_nwb=False,\n",
    "    focus_area_enabled=False,\n",
    "    focus_area_filepath=None,\n",
    "    grid_size=10,\n",
    "    include_variance=False,\n",
    "    mean_signal_threshold=10.0,\n",
    "    min_octave_span=1.0,\n",
    "    min_peak_count=2,\n",
    "    noise_window_size=200,\n",
    "    recording_filepath=None,\n",
    "    results_filepath=None,\n",
    "    roi_filepath=None,\n",
    "    roi_mode=ROIMode.GRID,\n",
    "    save_overview_png=True,\n",
    "    save_single_trace_results=False,\n",
    "    save_summary_results=True,\n",
    "    signal_to_noise_ratio=3.0,\n",
    "    start_frame_idx=0,\n",
    "    use_frame_range=False,\n",
    "    variance_window_size=15,\n",
    ")\n",
    "\n",
    "correct_peak_config = {\n",
    "    'frame_idx': 10,\n",
    "    'intensity': 10.0,\n",
    "    'amplitude': 10.0,\n",
    "    'delta_f_over_f': 10.0,\n",
    "    'has_neighboring_intersections': True,\n",
    "    'frame_idxs_of_neighboring_intersections': (1,2),\n",
    "    'area_under_curve': 10.0,\n",
    "    'peak_type': 'normal',\n",
    "}\n",
    "minimal_peak_config = {\n",
    "    'frame_idx': 10,\n",
    "    'intensity': 10.0,\n",
    "}\n",
    "\n",
    "def test_correct_config():\n",
    "    return Config.from_dict(**correct_general_config)\n",
    "\n",
    "def test_minimal_config():\n",
    "    return Config.from_dict(data_source_path=filepath)\n",
    "\n",
    "def test_config_with_specific_filepaths():\n",
    "    specific_config = correct_general_config.copy()\n",
    "    specific_config['data_source_path'] = None\n",
    "    specific_config['recording_filepath'] = filepath\n",
    "    specific_config['roi_filepath'] = filepath\n",
    "    specific_config['focus_area_filepath'] = filepath\n",
    "    return Config.from_dict(**specific_config)\n",
    "\n",
    "def test_config_with_specific_filepaths_list():\n",
    "    specific_config = correct_general_config.copy()\n",
    "    specific_config['data_source_path'] = None\n",
    "    specific_config['recording_filepath'] = filepath\n",
    "    specific_config['roi_filepath'] = [filepath, filepath]\n",
    "    specific_config['focus_area_filepath'] = filepath\n",
    "    return Config.from_dict(**specific_config)\n",
    "\n",
    "def test_config_to_json():\n",
    "    config = Config.from_dict(**example_general_config)\n",
    "    return config.to_json()\n",
    "\n",
    "# enumerators are special cases, so we need to check them separately\n",
    "def test_config_enum_from_str():\n",
    "    incorrect_config = correct_general_config.copy()\n",
    "    incorrect_config['baseline_estimation_method'] = 'asls'  # valid value for baseline_estimation_method\n",
    "    return Config.from_dict(**incorrect_config)\n",
    "\n",
    "def test_incorrect_config_enum_from_str():\n",
    "    incorrect_config = correct_general_config.copy()\n",
    "    incorrect_config['baseline_estimation_method'] = 'not_valid'  # invalid value for baseline_estimation_method\n",
    "    return Config.from_dict(**incorrect_config)\n",
    "\n",
    "# general invalid types checks\n",
    "def test_incorrect_config_batch_mode():\n",
    "    incorrect_config = correct_general_config.copy()\n",
    "    incorrect_config['batch_mode'] = 'invalid_value'  # invalid type for batch_mode\n",
    "    return Config.from_dict(**incorrect_config)\n",
    "\n",
    "def test_incorrect_config_end_frame_idx():\n",
    "    incorrect_config = correct_general_config.copy()\n",
    "    incorrect_config['end_frame_idx'] = 'invalid_value'  # invalid type for end_frame_idx\n",
    "    return Config.from_dict(**incorrect_config)\n",
    "\n",
    "# enumerators are special cases, so we need to check them separately\n",
    "def test_incorrect_config_baseline_estimation_method():\n",
    "    incorrect_config = correct_general_config.copy()\n",
    "    incorrect_config['baseline_estimation_method'] = 1337  # invalid type for baseline_estimation_method\n",
    "    return Config.from_dict(**incorrect_config)\n",
    "\n",
    "# boolean fields are also special cases, so we need to check them separately\n",
    "def test_incorrect_config_customize_octave_filtering():\n",
    "    incorrect_config = correct_general_config.copy()\n",
    "    incorrect_config['customize_octave_filtering'] = 'invalid_value'  # invalid type for customize_octave_filtering\n",
    "    return Config.from_dict(**incorrect_config)\n",
    "\n",
    "# roi_filepath is a special case, so we need to check it separately\n",
    "def test_incorrect_config_roi_filepath():\n",
    "    incorrect_config = correct_general_config.copy()\n",
    "    incorrect_config['roi_filepath'] = (1, 2)  # invalid type for roi_filepath\n",
    "    return Config.from_dict(**incorrect_config)\n",
    "\n",
    "# other filepaths should not be set up with data_source_path\n",
    "def test_incorrect_config_singular_path():\n",
    "    incorrect_config = correct_general_config.copy()\n",
    "    incorrect_config['recording_filepath'] = filepath\n",
    "    incorrect_config['roi_filepath'] = filepath\n",
    "    incorrect_config['focus_area_filepath'] = filepath\n",
    "    return Config.from_dict(**incorrect_config)\n",
    "\n",
    "def test_correct_peak_config():\n",
    "    return Peak.from_dict(**correct_peak_config)\n",
    "\n",
    "def test_minimal_peak_config():\n",
    "    return Peak.from_dict(**minimal_peak_config)\n",
    "\n",
    "def test_incomplete_peak_config():\n",
    "    incomplete_peak_config = correct_peak_config.copy()\n",
    "    incomplete_peak_config.pop('frame_idx')\n",
    "    return Peak.from_dict(**incomplete_peak_config)\n",
    "\n",
    "def test_wrong_peak_config():\n",
    "    wrong_peak_config = correct_peak_config.copy()\n",
    "    wrong_peak_config['frame_idx'] = 'invalid_value'\n",
    "    return Peak.from_dict(**wrong_peak_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3605d42a-e917-4993-b6d0-7969036365ce",
   "metadata": {},
   "source": [
    "Run tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2074613d837e3967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct inputs tests\n",
    "assert isinstance(test_correct_config(), Config)\n",
    "assert isinstance(test_minimal_config(), Config)\n",
    "assert isinstance(test_config_enum_from_str(), Config)\n",
    "assert isinstance(test_config_with_specific_filepaths(), Config)\n",
    "assert isinstance(test_config_with_specific_filepaths_list(), Config)\n",
    "assert isinstance(test_correct_peak_config(), Peak)\n",
    "assert isinstance(test_minimal_peak_config(), Peak)\n",
    "assert test_config_to_json() == dumps(example_general_config)\n",
    "\n",
    "# incomplete inputs tests\n",
    "test_fail(test_incomplete_peak_config)\n",
    "\n",
    "# wrong inputs tests\n",
    "test_fail(test_incorrect_config_batch_mode)\n",
    "test_fail(test_incorrect_config_baseline_estimation_method)\n",
    "test_fail(test_incorrect_config_customize_octave_filtering)\n",
    "test_fail(test_incorrect_config_end_frame_idx)\n",
    "test_fail(test_incorrect_config_roi_filepath)\n",
    "test_fail(test_incorrect_config_singular_path)\n",
    "test_fail(test_incorrect_config_enum_from_str)\n",
    "test_fail(test_wrong_peak_config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
